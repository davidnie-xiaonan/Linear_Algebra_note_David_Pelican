<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linear Algebra Note - David Nie</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/" rel="alternate"></link><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/feeds/david-nie.atom.xml" rel="self"></link><id>https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/</id><updated>2021-12-05T19:30:00-05:00</updated><subtitle>By David Nie</subtitle><entry><title>1-1 About this note</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/1-1-about-this-note" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/1-1-about-this-note</id><summary type="html">&lt;h1 id="a-welcome-from-david"&gt;A Welcome from David&lt;a class="headerlink" href="#a-welcome-from-david" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Hello everybody! I am very happy that you chose to go through my&amp;nbsp;note.&lt;/p&gt;
&lt;p&gt;Linear algebra is a fantastic branch of math and no need to say, most of the students don&amp;#8217;t understand what is going on even after the final exam of freshman yea …&lt;/p&gt;</summary><content type="html">&lt;h1 id="a-welcome-from-david"&gt;A Welcome from David&lt;a class="headerlink" href="#a-welcome-from-david" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Hello everybody! I am very happy that you chose to go through my&amp;nbsp;note.&lt;/p&gt;
&lt;p&gt;Linear algebra is a fantastic branch of math and no need to say, most of the students don&amp;#8217;t understand what is going on even after the final exam of freshman yea&amp;#8217;s linear&amp;nbsp;algebra. &lt;/p&gt;
&lt;p&gt;I want this note to be useful to you if you are a grade 12 student, and you are willing to challenge yourself. Or you could be a first-year university student struggling in this course and you want to pass the&amp;nbsp;course. &lt;/p&gt;
&lt;p&gt;Or you could be a second or third-year &lt;span class="caps"&gt;STEM&lt;/span&gt; student and already learned all the concepts but willing to get a better understanding of how linear algebra applies in your&amp;nbsp;field.&lt;/p&gt;
&lt;p&gt;Finally, I also want this note to be useful even if you are a &lt;span class="caps"&gt;TA&lt;/span&gt; or a high school teacher who teach relevant concepts. so you might find some new perspectives or interesting examples that you can apply in your own&amp;nbsp;teaching.&lt;/p&gt;
&lt;h1 id="what-can-you-get-from-this-note"&gt;What can you get from this note&lt;a class="headerlink" href="#what-can-you-get-from-this-note" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;First of all, Linear algebra meant to be a university-level course, so you should understand is that the course itself is not easy. Also, since Linear algebra has impacts on so many fields such as statistics, economy, physics, computer science, this note will touch a lot of different concepts/examples from other&amp;nbsp;fields.&lt;/p&gt;
&lt;p&gt;Nevertheless, this is a &amp;#8220;note&amp;#8221; of linear algebra, one should not expect to only use this as the reference. However, this note can give you an easier, more practical approach to linear&amp;nbsp;algebra. &lt;/p&gt;
&lt;p&gt;Instead of introducing all the different concepts from nothing and force students to memorize the detail, we are trying something different&amp;nbsp;here. &lt;/p&gt;
&lt;p&gt;Every chapter will begin with motivation and each concept will be explained not by proof. To see the proof, you can go through the textbook or search online. Here, we only focus on the true purpose of introducing the new idea and how is this new idea helps us in different&amp;nbsp;ways.&lt;/p&gt;
&lt;p&gt;Of course, practice makes perfect, so each chapter will be followed by a relatively big problem set. Each of the questions in the problem set will have a simple&amp;nbsp;explanation.&lt;/p&gt;
&lt;p&gt;Hopefully, everyone can get a much better understanding after reading the note and be able to perform some useful calculations. In the end, I would like to quote what Dieudonné said in his &amp;#8220;Foundations of Modern Analysis, Vol.&amp;nbsp;1&amp;#8221;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is hardly any theory which is more elementary (than linear algebra), in spite of the fact that generations of professors and textbook writers have obscured its simplicity by preposterous calculations with&amp;nbsp;matrices.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="Chapter 1"></category></entry><entry><title>1-2 prereq</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/1-2-prereq" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/1-2-prereq</id><summary type="html">&lt;p&gt;One of the fascinate thing about Linear Algebra is that the prerequisites of this course is nearly nothing. When I first learn the linear algebra, I was amazed by the fact that you can do so many thing with just some simple integer number operation. But to catch the essence …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the fascinate thing about Linear Algebra is that the prerequisites of this course is nearly nothing. When I first learn the linear algebra, I was amazed by the fact that you can do so many thing with just some simple integer number operation. But to catch the essence of linear algebra, we need to review some basic algebra that everybody do in grade 8: The linear&amp;nbsp;equation.&lt;/p&gt;
&lt;p&gt;We all learned the linear equations, the simple algebraic expression that somehow describe the shape of a line in Cartesian plane. The algebra&amp;nbsp;expression:&lt;/p&gt;
&lt;div class="math"&gt;$$y=mx+b$$&lt;/div&gt;
&lt;p&gt;We call this slope-intercept form. We can also rearrange the equation and write down the same thing with a expression looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="math"&gt;$$ax+by=c$$&lt;/div&gt;
&lt;p&gt;both form are telling the same relation between variable &lt;span class="math"&gt;\(x\)&lt;/span&gt; and variable &lt;span class="math"&gt;\(y\)&lt;/span&gt; and if we draw all the pair of &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; as a coordinate in Cartesian plane, we will get a 2d line. all the &lt;span class="math"&gt;\(a\)&lt;/span&gt;,&lt;span class="math"&gt;\(b\)&lt;/span&gt;,&lt;span class="math"&gt;\(c\)&lt;/span&gt;,&lt;span class="math"&gt;\(m\)&lt;/span&gt;,&lt;span class="math"&gt;\(b\)&lt;/span&gt; are just some numbers. for&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$5x+2y =3$$&lt;/div&gt;
&lt;p&gt;Now lets do some algebra. Say we have two lines, let&amp;#8217;s call them line A and line B. the top equation is the equation for line A and line B&amp;nbsp;is:&lt;/p&gt;
&lt;div class="math"&gt;$$2x+y = 1$$&lt;/div&gt;
&lt;p&gt;Without graphing them out, how would you find the intercept of two&amp;nbsp;lines? &lt;/p&gt;
&lt;p&gt;The question itself is fairly easy, we can use substitution or elimination to find the specific &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; value that both satisfy the equation for line A and line B, and that is the coordinate of the&amp;nbsp;intercept.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s start with substitution, we first take the second equation and move &lt;span class="math"&gt;\(2x\)&lt;/span&gt; to the other&amp;nbsp;side:&lt;/p&gt;
&lt;div class="math"&gt;$$y = 1-{\color{red}{2x}} $$&lt;/div&gt;
&lt;p&gt;then we can substitute &lt;span class="math"&gt;\(y\)&lt;/span&gt; into our first&amp;nbsp;equation:&lt;/p&gt;
&lt;div class="math"&gt;$$5x+ 2{\color{red}{(1-2x)}} = 3 $$&lt;/div&gt;
&lt;div class="math"&gt;$$5x+2-4x = 3$$&lt;/div&gt;
&lt;div class="math"&gt;$$x=1$$&lt;/div&gt;
&lt;p&gt;Then we grab the result and replace the &lt;span class="math"&gt;\(x\)&lt;/span&gt; to 1 in either the first or the second equation, we can solve the &lt;span class="math"&gt;\(y\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$y=1-2*{\color{red}{1}} = -1$$&lt;/div&gt;
&lt;hr /&gt;
&lt;p&gt;Now let&amp;#8217;s do the same question but with elimination. The idea is this: the goal is to solve &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, but what makes this hard to achieve is the fact that we got two variables in one equation. So, if I can get rid of one variable, we are in a good shape. Can we do that? Sure! Take equation of line B and multiply everything by a factor of&amp;nbsp;2:&lt;/p&gt;
&lt;div class="math"&gt;$$2x+y = 1 \Rightarrow 4x+2y = 2$$&lt;/div&gt;
&lt;p&gt;Then take the equation for line A and subtract the new equation we&amp;nbsp;got:&lt;/p&gt;
&lt;div class="math"&gt;$$5x+2y - \color{red}{(4x+2y)} = 3-\color{red}2$$&lt;/div&gt;
&lt;p&gt;Do a little algebra we can see all the &lt;span class="math"&gt;\(y\)&lt;/span&gt; canceled and we left&amp;nbsp;with:&lt;/p&gt;
&lt;div class="math"&gt;$$x=1$$&lt;/div&gt;
&lt;p&gt;Repeat what we did in substitution we will end up with the same&amp;nbsp;result. &lt;/p&gt;
&lt;h2 id="2-three-dimensional-plane"&gt;2. Three dimensional plane&lt;a class="headerlink" href="#2-three-dimensional-plane" title="Permanent link"&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now we moved on to Three dimension. Don&amp;#8217;t worry if you never study the math in 3d space before, it is not that different from 2d. One major difference is that two variable is not enough for us to describe the location of points in 3d space. Now we need three, and let&amp;#8217;s call the extra one &lt;span class="math"&gt;\(z\)&lt;/span&gt;. Imagine the 2d Cartesian coordinate is a blanket and you place the blanket on the floor, now &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; describe the position on the blanket and the new &lt;span class="math"&gt;\(z\)&lt;/span&gt; coordinate describe how high the point&amp;nbsp;is.&lt;/p&gt;
&lt;p&gt;And Ta-da! We can find the coordinate of any point in three dimensional plane! Now we know how to describe a point, some of you might ask, is the preview line equation still works in 3d? Sadly, no. The&amp;nbsp;equation:&lt;/p&gt;
&lt;div class="math"&gt;$$ax+by=c$$&lt;/div&gt;
&lt;p&gt;Only gives you the relation between &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, and there is no restriction on &lt;span class="math"&gt;\(z\)&lt;/span&gt; axis, which means that this equation describe not only the line on the blanket(x-y plane), but also many different lines on top of it or below it. So what it is? The combination of all the lines is a plane. To be more specific, a 2d plane in 3d space. In general, a equation looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="math"&gt;$$ax+by+cz = d$$&lt;/div&gt;
&lt;p&gt;describes a plane in 3d&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;But how do we describe a line in 3d space? You can use some math trick, say the intercepts of two plane. Or you can sue what we called vector, which happens to be our first new&amp;nbsp;concept.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 1"></category></entry><entry><title>2-1 Vector</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/2-1-vector" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/2-1-vector</id><summary type="html">&lt;h1 id="what-is-a-vector-looks-like"&gt;What is a vector looks like?&lt;a class="headerlink" href="#what-is-a-vector-looks-like" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Linear algebra begin with a simple concept in physics, more specifically mechanics: the vector. Understanding vector is the first step to understand linear algebra. To do this, we have to visit three different place, since it has different meaning in different&amp;nbsp;field. &lt;/p&gt;
&lt;p&gt;In physics …&lt;/p&gt;</summary><content type="html">&lt;h1 id="what-is-a-vector-looks-like"&gt;What is a vector looks like?&lt;a class="headerlink" href="#what-is-a-vector-looks-like" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Linear algebra begin with a simple concept in physics, more specifically mechanics: the vector. Understanding vector is the first step to understand linear algebra. To do this, we have to visit three different place, since it has different meaning in different&amp;nbsp;field. &lt;/p&gt;
&lt;p&gt;In physics, &lt;strong&gt;vector is any quantity that has both direction and magnitude&lt;/strong&gt;. For example, energy as a physical quantity is not a vector because it has no specific direction, but velocity is a vector since it has both direction(where are you going) and magnitude(how fast are you&amp;nbsp;going).&lt;/p&gt;
&lt;p&gt;In computer science, vector as a data structure has a different name called array. &lt;strong&gt;An array, is a data structure consisting of a collection of elements (values or variables)&lt;/strong&gt;. For example, I have many data points like 1,2,3,4,5,6,7, and I want to multiply all of them by 2. In python, we can write this as a numpy&amp;nbsp;array:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;import numpy as np&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;x = np.array(1,2,3,4,5,6,7)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and just multiply them at&amp;nbsp;once:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;print(2*x)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; [2,4,6,8,10,12,14]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;But you might want to ask: What is the definition of a vector in mathematics? Take some guesses, We will reveal the answer at the end of this&amp;nbsp;chapter.&lt;/p&gt;
&lt;p&gt;In physics, a vector is usually placed in a coordinate system. For example, we can say a 2d vector called x in Cartesian plane to be (1,1), means that the vector is starting from the origin and pointing toward&amp;nbsp;Northeast. &lt;/p&gt;
&lt;p&gt;&lt;img alt="vector1" src="../images/vector1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Notice that the starting point of a vector is not important, we can freely moved the vector without changing it as long as it maintain the shape. Reason is simple, changing starting point don&amp;#8217;t change its direction or&amp;nbsp;magnitude.&lt;/p&gt;
&lt;p&gt;Because of that, we usually place it right on the origin and use the tip coordinate to describe the&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;You can compute the length of this vector using Pythagorean theorem. In our case, the result&amp;nbsp;is:&lt;/p&gt;
&lt;div class="math"&gt;$$ Length = |\vec{x}| = \sqrt{1^2+1^2} = \sqrt{2} $$&lt;/div&gt;
&lt;p&gt;I put a little bar on the top of variable &lt;span class="math"&gt;\(\vec{x}\)&lt;/span&gt; just to clarify that &lt;span class="math"&gt;\(\vec{x}\)&lt;/span&gt; is a vector. Usually, If you don&amp;#8217;t do that, we think the &lt;span class="math"&gt;\(x\)&lt;/span&gt; is a &lt;strong&gt;Scalar&lt;/strong&gt;. In physics, a scalar is a quantity that do not have a direction, like a number in&amp;nbsp;math. &lt;/p&gt;
&lt;p&gt;To write down the vector, we do the same thing that computer science people does: putting two or more numbers together. Once we have the vector written down, we can treat the numbers as coordinate, compute the direction and the length of the vector if we want to do&amp;nbsp;that.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 2 Vectors in n dimension"></category></entry><entry><title>2-2 Adding vector</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/2-2-adding-vector" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/2-2-adding-vector</id><summary type="html">&lt;h1 id="vector-addition-subtraction-and-scalar-multiplication"&gt;Vector addition, subtraction and Scalar multiplication&lt;a class="headerlink" href="#vector-addition-subtraction-and-scalar-multiplication" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Like numbers, you can also add and subtract vectors. But what is the meaning of adding or subtracting two vector, and how do we do&amp;nbsp;that?&lt;/p&gt;
&lt;p&gt;Imaging you are walking on a 2d plane and you start at the origin. Say there is a …&lt;/p&gt;</summary><content type="html">&lt;h1 id="vector-addition-subtraction-and-scalar-multiplication"&gt;Vector addition, subtraction and Scalar multiplication&lt;a class="headerlink" href="#vector-addition-subtraction-and-scalar-multiplication" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Like numbers, you can also add and subtract vectors. But what is the meaning of adding or subtracting two vector, and how do we do&amp;nbsp;that?&lt;/p&gt;
&lt;p&gt;Imaging you are walking on a 2d plane and you start at the origin. Say there is a penny located at (2,2) and you are about to pick it up. So you walk to the position (2,2). Let us record this motion using vector and write this vector &lt;span class="math"&gt;\(a\)&lt;/span&gt;&amp;nbsp;as:&lt;/p&gt;
&lt;div class="math"&gt;$$ \vec{a} = (2,2)$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w2vector1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2vector1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Then you heard someone yelling at you. The sound is coming from your right. So you walk to this person and return the penny to him unwillingly. Notice that if you look from above, the direction of this motion is Southeast because your moving direction is Northeast at the beginning. For simplicity, let say you walked exactly &lt;span class="math"&gt;\(\sqrt{2}\)&lt;/span&gt;&amp;nbsp;unit.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2vector2" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2vector2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now we need to see what is you second motion. As we learned before, moving a vector don&amp;#8217;t change the vector itself, so if we move this vector and place it on the origin, we can see the tip of the vector land exactly on the point&amp;nbsp;(1,-1).&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2gif1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2gif1.gif" /&gt;&lt;/p&gt;
&lt;p&gt;So we do the same thing and record this motion using&amp;nbsp;vector:
&lt;/p&gt;
&lt;div class="math"&gt;$$ \vec{b} = (1,-1)$$&lt;/div&gt;
&lt;p&gt;Now we can finally ask ourselves: what is the meaning of adding this two vector &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt;? The answer is quite straightforward. The first motion is &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and right after that you did the second motion &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt;. If you combine these two motions and only look at the result of them, it looks like you just walked to the final point where you talked to the guy who thinks you stealed his&amp;nbsp;penny.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2gif2" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2gif2.gif" /&gt;&lt;/p&gt;
&lt;p&gt;So how do we calculate the result? It is very obvious to see that the tip of &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt; is sitting at point (3,1). Therefore the result is&amp;nbsp;just:&lt;/p&gt;
&lt;div class="math"&gt;$$\vec{a}+\vec{b}= \vec{c} = (3,1)$$&lt;/div&gt;
&lt;p&gt;If you watch carefully, you can find that the x coordinate of the result is just happens to be the result of adding both x&amp;nbsp;coordinate:&lt;/p&gt;
&lt;div class="math"&gt;$$c_x = a_x + b_x = 2+1 = 3$$&lt;/div&gt;
&lt;p&gt;Same as y&amp;nbsp;coordinate:&lt;/p&gt;
&lt;div class="math"&gt;$$c_y = a_y + b_y = 2-1 = 1$$&lt;/div&gt;
&lt;p&gt;The reason is because we placed everything inside the Cartesian&amp;nbsp;coordinate. &lt;/p&gt;
&lt;p&gt;If we treat the x coordinate and the y coordinate as vectors sitting exactly on the x and y axis, then every vector can be represent as an addition of those&amp;nbsp;vectors!&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2vectoradd" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2vectoradd.png" /&gt;&lt;/p&gt;
&lt;p&gt;Once we realized that, we can reverse the addition and break down our &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt;. Then we add all the x direction vectors, do the same thing on y direction vectors. We will end up with two sums, one for x direction and one for y direction. So, our job is done! Because the way we write down vector is just to write down their x and y&amp;nbsp;components.&lt;/p&gt;
&lt;div class="math"&gt;$$\vec{a}+\vec{b}= (\color{red}2,\color{blue}2) + (\color{red}1,\color{blue}{-1}) = (\color{red}3,\color{blue}1)$$&lt;/div&gt;
&lt;hr /&gt;
&lt;p&gt;Next we are going to do some multiplication. Just like number multiplication, the multiplication is just adding the same thing many many times. Luckily, we can also do that in vector. Again, take &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; from previous section as an&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$ 2\times\vec{a} = 2\times(\color{red}2,\color{red}2) = (2\times\color{red}2,2\times\color{red}2) = (4,4)$$&lt;/div&gt;
&lt;p&gt;We can also multiply a negative scalar like &lt;span class="math"&gt;\(-1\)&lt;/span&gt;. Keep in mind, multiply negative value will reverse the direction of the vector.
&lt;img alt="w2negative" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2negative.gif" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;So far we know how to add any two vectors and multiply any vector with a scalar, it is a good time to introduce the&amp;nbsp;subtraction. &lt;/p&gt;
&lt;p&gt;To calculate, it is fairly easy. As you expected, instead of adding the coordinate like you did before, this time you just&amp;nbsp;subtract:&lt;/p&gt;
&lt;div class="math"&gt;$$\vec{a}-\vec{b} = (2,2)-(1,-1) = (1,3)$$&lt;/div&gt;
&lt;p&gt;To visualize it just like we did for addition, we can break down subtraction into addition and multiplication of &lt;span class="math"&gt;\(-1\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\vec{a}-\vec{b} = \vec{a} + (\color{red}{-1}\times\vec{b})$$&lt;/div&gt;
&lt;p&gt;
&lt;img alt="w2subtract" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2subtract.gif" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;And that is the end of the first&amp;nbsp;chapter! &lt;/p&gt;
&lt;p&gt;You will see more examples and fun applications in the assignment. The addition and subtraction rules looks easy but it has a huge impact to more important concepts like linear combination, span, and&amp;nbsp;basis. &lt;/p&gt;
&lt;p&gt;Now it is the time to reveal the answer of the question I gave from the previous chapter: What is a vector in&amp;nbsp;mathematics? &lt;/p&gt;
&lt;p&gt;Well, mathematics people tend to have a more abstract definition. In short, vector is the object that follows the rules of vector addition and the scalar multiplication. Or you can say that vector is an element of vector space. What is a vector space? Well, we will go back to this topic. For now, you can think of vector space as a realm that has those rules we mentioned&amp;nbsp;above.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 2 Vectors in n dimension"></category></entry><entry><title>2-3 Assignment</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/2-3-assignment" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/2-3-assignment</id><summary type="html">&lt;p&gt;1.Two vectors &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt; are located at the origin as showing&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2q1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1_question.png" /&gt;&lt;/p&gt;
&lt;p&gt;(a) Find the vector &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt; using the vector subtraction law, and then calculate its magnitude and direction.(you can use angle to describe the&amp;nbsp;direction)&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;(b) Without using the result from …&lt;/p&gt;</summary><content type="html">&lt;p&gt;1.Two vectors &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt; are located at the origin as showing&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2q1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1_question.png" /&gt;&lt;/p&gt;
&lt;p&gt;(a) Find the vector &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt; using the vector subtraction law, and then calculate its magnitude and direction.(you can use angle to describe the&amp;nbsp;direction)&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;(b) Without using the result from (a) and the law, find the magnitude and the direction of &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;(c) compare your result from part(a) and part(b). Ask yourself which one you&amp;nbsp;prefer.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;2.You are play chess on a 2d Cartesian plane. Say your knight is located at the corner of the chess board(the origin) and there is a juicy queen sitting at (6,8). Reminder: The knight&amp;#8217;s movement is unique: it may move two squares vertically and one square horizontally, or two squares horizontally and one square vertically (with both forming the shape of an&amp;nbsp;L).&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2q2_question" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q2_question.png" /&gt;&lt;/p&gt;
&lt;p&gt;(a) Let&amp;#8217;s assume your opponent is quite dumb, so he just don&amp;#8217;t like to move the queen. Now how do you move your knight to kill the&amp;nbsp;queen? &lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;(b) We can use the vector notation to explain the movement of knight. For example, if we want to move the knight to (3,3), we can&amp;nbsp;do:&lt;/p&gt;
&lt;div class="math"&gt;$$(3,3) = 1*(2,1) + 1*(1,2)$$&lt;/div&gt;
&lt;p&gt;Now, rewrite your result from (a) using vector addition and scalar&amp;nbsp;multiplication.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;(c) Can you proof that knight can go to any location on the chess&amp;nbsp;board?&lt;/p&gt;
&lt;h2 id="-"&gt;&amp;#8212;-&lt;a class="headerlink" href="#-" title="Permanent link"&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;h1 id="answer-sheet"&gt;Answer sheet&lt;a class="headerlink" href="#answer-sheet" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Two vectors &lt;span class="math"&gt;\(\vec{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\vec{b}\)&lt;/span&gt; are located at the origin as showing&amp;nbsp;below:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="w2q1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1_question.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(a) Find the vector &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt; using the vector subtraction law, and then calculate its magnitude and direction.(you can use angle to describe the&amp;nbsp;direction)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;By using subtraction law, we can easily&amp;nbsp;get:&lt;/p&gt;
&lt;div class="math"&gt;$$\vec{a}-\vec{b} = (3,4) - (2,-2) = (1,6)$$&lt;/div&gt;
&lt;p&gt;We can find the magnitude using Pythagorean&amp;nbsp;theorem:&lt;/p&gt;
&lt;div class="math"&gt;$$|\vec{a}-\vec{b}| = \sqrt{1^2+6^2} = \sqrt{37} = 6.082$$&lt;/div&gt;
&lt;p&gt;To find the direction, we can use the inverse trig&amp;nbsp;function:&lt;/p&gt;
&lt;div class="math"&gt;$$\theta = \arctan(6/1) = \arctan(6) $$&lt;/div&gt;
&lt;p&gt;And that is roughly East 80.5 degree North.
&lt;img alt="w2q1_ans" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1_ans.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(b) Without using the law of vector addition and subtraction, find the magnitude and the direction of &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This time no subtraction allowed. One way we can solve this is to use the cosine&amp;nbsp;law.&lt;/p&gt;
&lt;p&gt;we began with solving the magnitude of both &lt;span class="math"&gt;\(\vec{a} $ and $\vec{b}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ |\vec{a}| = \sqrt{3^2+4^2} = 5$$&lt;/div&gt;
&lt;div class="math"&gt;$$ |\vec{b}| = \sqrt{2^2+-2^2} = 2\sqrt{2}$$&lt;/div&gt;
&lt;p&gt;Then we find the angle between&amp;nbsp;them:&lt;/p&gt;
&lt;div class="math"&gt;$$\theta = 53^\circ + 45^\circ = 98^\circ $$&lt;/div&gt;
&lt;p&gt;
&lt;img alt="w2q1p2" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1p2.png" /&gt;&lt;/p&gt;
&lt;p&gt;then we use cosine&amp;nbsp;law:&lt;/p&gt;
&lt;div class="math"&gt;$$ c^2 = a^2 + b^2 - 2ab\cos(\theta)$$&lt;/div&gt;
&lt;div class="math"&gt;$$ c = \sqrt{25+8-2\times5\times2\sqrt{2}\times \cos({98^\circ}}) = \sqrt{36.96} = 6.079$$&lt;/div&gt;
&lt;p&gt;To get the angle, we can first use sine law to get the angle for other two angle in the&amp;nbsp;triangle:&lt;/p&gt;
&lt;div class="math"&gt;$$\angle{A} = \arcsin(\frac{\sin(98^\circ)\times5}{6.079})= 54.5^\circ$$&lt;/div&gt;
&lt;p&gt;
&lt;img alt="w2q1p22" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q1p22.png" /&gt;&lt;/p&gt;
&lt;p&gt;Then we can calculate the angle between &lt;span class="math"&gt;\(\vec{a}-\vec{b}\)&lt;/span&gt; and the horizontal&amp;nbsp;line:&lt;/p&gt;
&lt;div class="math"&gt;$$\theta = 180^\circ-45^\circ-54.5^\circ = 80.5^\circ$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;(c) compare your result from part(a) and part(b). Ask yourself which one you&amp;nbsp;prefer.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no need to tell which one is easier. In practice, if we have chance to put vector in coordinate, we always do that&amp;nbsp;first.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You are play chess on a 2d Cartesian plane. Say your knight is located at the corner of the chess board(the origin) and there is a juicy queen sitting at (6,8). Reminder: The knight&amp;#8217;s movement is unique: it may move two squares vertically and one square horizontally, or two squares horizontally and one square vertically (with both forming the shape of an&amp;nbsp;L).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="w2q2_question" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q2_question.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(a) Let&amp;#8217;s assume your opponent is quite dumb, so he just don&amp;#8217;t like to move the queen. Now how do you move your knight to kill the&amp;nbsp;queen? &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are multiple ways to do this, here I will only show one way:
&lt;img alt="w2q2p1" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q2p1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(b) We can use the vector notation to explain the movement of knight. For example, if we want to move the knight to (3,3), we can&amp;nbsp;do:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$(3,3) = 1*(2,1) + 1*(1,2)$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Now, rewrite your result from (a) using vector addition and scalar&amp;nbsp;multiplication.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is also fairly straightforward, just read the vector from your graph and write them down as a collection of&amp;nbsp;vectors:&lt;/p&gt;
&lt;div class="math"&gt;$$(6,8) = 1*(-2,1) + 3*(2,1)+ 2*(1,2)$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;(c) Can you prove that knight can go to any location on the chess&amp;nbsp;board?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To prove the knight can go to any location, we have to design a path for any location (a,b). One way to do this is to find a path for the knight to go to (1,0), then repeat it a times to get to the position (a,0). After that, find a path for the knight to go to (0,1), then repeat it b times to get to the position (a,b). the below diagram shows how to jump to (1,0) and (0,1)&amp;nbsp;respectively.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w2q2p2" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q2p2.png" /&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$(1,0) = (1,2) + (2,-1)+ (-2,-1)$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w2q2p3" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w2q2p3.png" /&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$(0,1) = (2,1) + (-1,2)+ (-1,-2)$$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 2 Vectors in n dimension"></category></entry><entry><title>3-1 Linear combination of vectors</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/3-1-linear-combination-of-vectors" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/3-1-linear-combination-of-vectors</id><summary type="html">&lt;p&gt;From last chapter, we learned how to add and subtract vectors. We also know that how to expand or compress a vector using scalar multiplication. Now we can finally explain what is &amp;#8220;Linear&amp;#8221; in the word: linear&amp;nbsp;algebra. &lt;/p&gt;
&lt;p&gt;Say we have a set of many 2d vectors. Let&amp;#8217;s call …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From last chapter, we learned how to add and subtract vectors. We also know that how to expand or compress a vector using scalar multiplication. Now we can finally explain what is &amp;#8220;Linear&amp;#8221; in the word: linear&amp;nbsp;algebra. &lt;/p&gt;
&lt;p&gt;Say we have a set of many 2d vectors. Let&amp;#8217;s call&amp;nbsp;them:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{v}_1,\pmb{v}_2,\pmb{v}_3,\pmb{v}_4,...,\pmb{v}_n$$&lt;/div&gt;
&lt;p&gt;I have changed the notation a bit, instead of putting a little arrow on the letter, I just bold the&amp;nbsp;symbols. &lt;/p&gt;
&lt;p&gt;Notice that every single one of them has to be in a 2d Cartesian plane, because we cannot add 2d vector and 3d vector. Then, I pick few of them, randomly expand or compress them by multiplying some numbers. Then add everything up. At the end, I would expect the vector to be another 2d vector, let&amp;#8217;s call it &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{a} = c_1\pmb{v}_1+c_2\pmb{v}_2+c_3\pmb{v}_3+...+c_n\pmb{v}_n$$&lt;/div&gt;
&lt;p&gt;the set of numbers &lt;span class="math"&gt;\(c_1,c_2,c_3,...,c_n\)&lt;/span&gt; tells you how you expand or compress each vector. For example, I want to create a vector that is just half of the vector &lt;span class="math"&gt;\(\pmb{v}_1\)&lt;/span&gt;, then we can&amp;nbsp;do:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{a} = 0.5\pmb{v}_1+0\pmb{v}_2+0\pmb{v}_3+...+0\pmb{v}_n$$&lt;/div&gt;
&lt;p&gt;If this is how you construct vector &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt;, we say that &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt; is a &lt;strong&gt;Linear combination&lt;/strong&gt; of &lt;span class="math"&gt;\(\pmb{v}_1,\pmb{v}_2,\pmb{v}_3,\pmb{v}_4,...,\pmb{v}_n\)&lt;/span&gt;. The word &amp;#8220;Linear&amp;#8221; just means you only used the vector addition and scalar multiplication to create your vector. We will see why this is called &amp;#8220;Linear&amp;#8221; later. Spoil alert! it has something to do with how space change after certain&amp;nbsp;operation.&lt;/p&gt;
&lt;p&gt;Now, what is so great about this linear combination? Well, a lot of ideas are coming from the linear combination, it is just we don&amp;#8217;t call it that way&amp;nbsp;before. &lt;/p&gt;
&lt;p&gt;For example, you can get any point(vector) on a line by multiplying a vector. We can say it is just the linear combination of that vector. Similarly, you can get any point(vector) on a plane by &amp;#8220;linear&amp;#8221; combining two vectors. This is exactly how we construct the 2d Cartesian plane, by combining vector (1,0) and&amp;nbsp;(0,1)! &lt;/p&gt;
&lt;p&gt;Later on, you will see that the above examples will can be explained using the new concepts in linear&amp;nbsp;algebra. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term='Chapter 3 Meaning of "Linear" in linear algebra'></category></entry><entry><title>3-2 Span of vectors and space</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/3-2-span-of-vectors-and-space" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/3-2-span-of-vectors-and-space</id><summary type="html">&lt;p&gt;As we just learned from last section, we can create a new vector by linear combining other vectors. But why do need this tool at&amp;nbsp;all?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s go back to the beginning. Before we learn any linear algebra, we mentioned the lines in three dimension space. We find that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As we just learned from last section, we can create a new vector by linear combining other vectors. But why do need this tool at&amp;nbsp;all?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s go back to the beginning. Before we learn any linear algebra, we mentioned the lines in three dimension space. We find that describing lines in 2d Cartesian plane is much easier than do the same thing in 3d space. So can we find a new way to describe lines, planes or even space using linear&amp;nbsp;combination?&lt;/p&gt;
&lt;p&gt;Of course! But there is one thing we need to consider. The linear combination of vectors will only give you another vector, but we want more than just one&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;For example, if I have a vector in 2d&amp;nbsp;plane:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pmb{v} = (1,2) $$&lt;/div&gt;
&lt;p&gt;if we do a linear combination of only this vector, we can get a new vector by scalar&amp;nbsp;multiplication:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pmb{v}_{new} = (1,2)\times2 = (2,4)$$&lt;/div&gt;
&lt;p&gt;we can do this for other numbers too, but you will see that no matter how you change the number, you will always end up with the vector on the same&amp;nbsp;line.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w3vectors" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w3vectors.png" /&gt;&lt;/p&gt;
&lt;p&gt;If you collect all the possible linear combination, you will just get a&amp;nbsp;line. &lt;/p&gt;
&lt;p&gt;In linear algebra, we have a specific name for such collection of vectors: The &lt;strong&gt;span of vector&amp;nbsp;(2,1)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, let&amp;#8217;s see what can we get if we span two vector. For example, the span of vector (1,0) and (0,1). You will soon realize that one can easily get any vector in 2d plane by linear combining (1,0) and&amp;nbsp;(0,1):&lt;/p&gt;
&lt;div class="math"&gt;$$(a,b) = a(1,0) + b(0,1)$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w3spanspace" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w3spanspace.gif" /&gt;&lt;/p&gt;
&lt;p&gt;So, span of vector (1,0) and (0,1) will give you the whole 2d&amp;nbsp;plane. &lt;/p&gt;
&lt;p&gt;You can imaging that if we graph the span of more vectors, we can end up with any multidimensional&amp;nbsp;space. &lt;/p&gt;
&lt;p&gt;For example, to describe a three dimension space, we can pick three vectors lying in the&amp;nbsp;space:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{v}_1 = (1,0,0)$$&lt;/div&gt;
&lt;div class="math"&gt;$$\pmb{v}_2 = (0,1,0)$$&lt;/div&gt;
&lt;div class="math"&gt;$$\pmb{v}_3 = (0,0,1)$$&lt;/div&gt;
&lt;p&gt;To get any vector lying in the space, we can do a linear combination of the three&amp;nbsp;vector:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{v} = a_1\pmb{v}_1+a_2\pmb{v}_2+a_3\pmb{v}_3$$&lt;/div&gt;
&lt;p&gt;What if we span only two vectors in 3d space? Well, just like what happens in 2d plane, &lt;strong&gt;most of the time&lt;/strong&gt;, we will also get a plane in 2d&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;But, what if we span two colinear vectors? If we look at the image above, we can see that spanning vector (1,2) and a same 
direction vector (2,4) will not give you a whole plane. All the linear combinations of these two vector will just sitting on the same&amp;nbsp;line.&lt;/p&gt;
&lt;p&gt;So, spanning two vectors will not always give you 2d plane, sometime it could be a line, sometime even just a zero&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;Now you might ask, if I want to span two vector to get a plane, or I want to span three vector to get a 3d space, how should I select my vectors? This question is fairly easy to answer in 2d: just don&amp;#8217;t pick the vectors that sit on the same line. But we need a better answer when we raise the&amp;nbsp;dimension. &lt;/p&gt;
&lt;p&gt;In short, we want to have all the vector to be &amp;#8220;unique&amp;#8221;, means they were not the linear combination of other vectors. Of course, we have another fancy name for this kind of vectors: we call them &lt;strong&gt;&amp;#8220;Linear Independent vectors&amp;#8221;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For&amp;nbsp;example:&lt;/p&gt;
&lt;p&gt;In 2d, There is no way you can linear combine (1,0) to get (0,1), so they are linear independent. But you cannot say that (0,1) and (0,4) are linear independent vectors, because you can write (0,4) to be a linear combination of vector&amp;nbsp;(0,1):&lt;/p&gt;
&lt;div class="math"&gt;$$(0,4) = 4(0,1)$$&lt;/div&gt;
&lt;p&gt;If that is the case, we call them &lt;strong&gt;&amp;#8220;Linear Dependent vectors&amp;#8221;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In 3d, things are getting a little more complicated, because finding one vector is the linear combination of other two algebraically are not easy. So, we need more useful tools to calculate. However, we can see what happens when we have one vector is the linear combination of other two in 3d space. Let&amp;#8217;s look at the graph&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w3spanplane" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w3spanplane.png" /&gt;&lt;/p&gt;
&lt;p&gt;The vectors shown above&amp;nbsp;are:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pmb{v}_1 = (1,1,-2) $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \pmb{v}_2 = (-1,2,5) $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \pmb{v}_3 = (0,1,1) $$&lt;/div&gt;
&lt;p&gt;To proof one vector is the linear combination of other two, we can rewrite &lt;span class="math"&gt;\(\pmb{v}_1\)&lt;/span&gt; as&amp;nbsp;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \pmb{v}_1 = 3\pmb{v}_3-\pmb{v}_2 $$&lt;/div&gt;
&lt;p&gt;Unlike the colinear vector in 2d space, linear independent vector in 3d can be visualize as the vector that sit on the plane spanned by other two&amp;nbsp;vector.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term='Chapter 3 Meaning of "Linear" in linear algebra'></category></entry><entry><title>3-3 Basis of space</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/3-3-basis-of-space" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/3-3-basis-of-space</id><summary type="html">&lt;p&gt;Finally, we are can talk about the building block of N-dimension space: The basis. As we learned from last section, we can linear combine a set of vectors to form a line, a plane, or even space. Also, we knew that there is a restriction. Combine these two idea, we …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Finally, we are can talk about the building block of N-dimension space: The basis. As we learned from last section, we can linear combine a set of vectors to form a line, a plane, or even space. Also, we knew that there is a restriction. Combine these two idea, we will have our definition of&amp;nbsp;basis:&lt;/p&gt;
&lt;p&gt;We called a set of vectors &lt;span class="math"&gt;\(\pmb{S}\)&lt;/span&gt; is a basis of vector space &lt;span class="math"&gt;\(V\)&lt;/span&gt; if every element in &lt;span class="math"&gt;\(V\)&lt;/span&gt; can be written as a unique &lt;strong&gt;linear combination&lt;/strong&gt; of vectors in &lt;span class="math"&gt;\(\pmb{S}\)&lt;/span&gt; and all the vectors in &lt;span class="math"&gt;\(\pmb{S}\)&lt;/span&gt; is &lt;strong&gt;linear independent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For example, &lt;span class="math"&gt;\(set[(0,1),(1,0)]\)&lt;/span&gt; is a basis of 2d vector space (real vector space) since any vector in the vector space (a,b) can be written as a unique linear combination of &lt;span class="math"&gt;\((0,1)\)&lt;/span&gt; and &lt;span class="math"&gt;\((1,0)\)&lt;/span&gt;. Not only that, &lt;span class="math"&gt;\((0,1)\)&lt;/span&gt; and &lt;span class="math"&gt;\((1,0)\)&lt;/span&gt; cannot be written as a linear combination of each others, so they are linear&amp;nbsp;independent.&lt;/p&gt;
&lt;p&gt;If the set spans the vector space but the vectors in it are not linear independent. We can still called them the generating set or the spanning set of vector space. The name comes from the fact that the vectors &amp;#8220;generate&amp;#8221; the whole&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;In linear algebra, we can use the basis to represent the corresponding vector space. But what is the actual difference between two different basis if they describe the exact same vector&amp;nbsp;space?&lt;/p&gt;
&lt;p&gt;We can construct the 2d Cartesian plane use &lt;span class="math"&gt;\(set[(0,1),(1,0)]\)&lt;/span&gt;, we can also do the same thing with &lt;span class="math"&gt;\(set[(1,1),(1,0)]\)&lt;/span&gt;. So what is the point of writing vector space in terms of different basis? Is it just for&amp;nbsp;fun?&lt;/p&gt;
&lt;p&gt;Answer is of course not. In fact, this idea of presenting vector space in different basis is a huge topic in linear algebra. Change basis of a vector space will simultaneously change all the vectors in that space. To understand how the vector change in space, we have to learn the &amp;#8220;essence&amp;#8221; of linear algebra: the linear&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w3changebasis" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w3changebasis.gif" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term='Chapter 3 Meaning of "Linear" in linear algebra'></category></entry><entry><title>3-4 Assignment</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/3-4-assignment" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/3-4-assignment</id><summary type="html">&lt;p&gt;1.Let &lt;span class="math"&gt;\(A\)&lt;/span&gt;, &lt;span class="math"&gt;\(B\)&lt;/span&gt; be two vectors in 2d real vector space &lt;span class="math"&gt;\(\mathbb{R}_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(a)If &lt;span class="math"&gt;\(A = (1,2)\)&lt;/span&gt; and &lt;span class="math"&gt;\(B = (1,4)\)&lt;/span&gt;, are they linear independent or not? If they are, can you write (4,4) as a linear combination of &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;(b) If &lt;span class="math"&gt;\(A = (x …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;1.Let &lt;span class="math"&gt;\(A\)&lt;/span&gt;, &lt;span class="math"&gt;\(B\)&lt;/span&gt; be two vectors in 2d real vector space &lt;span class="math"&gt;\(\mathbb{R}_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(a)If &lt;span class="math"&gt;\(A = (1,2)\)&lt;/span&gt; and &lt;span class="math"&gt;\(B = (1,4)\)&lt;/span&gt;, are they linear independent or not? If they are, can you write (4,4) as a linear combination of &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;(b) If &lt;span class="math"&gt;\(A = (x,y)\)&lt;/span&gt; and &lt;span class="math"&gt;\(B = (x,2y)\)&lt;/span&gt;, what &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; value will make &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt; linear&amp;nbsp;dependent?&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;2.Let &lt;span class="math"&gt;\(C\)&lt;/span&gt;, &lt;span class="math"&gt;\(D\)&lt;/span&gt;, and &lt;span class="math"&gt;\(E\)&lt;/span&gt; be three vectors in 3d real vector space &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(a) Let &lt;span class="math"&gt;\(C=(1,2,3)\)&lt;/span&gt;, &lt;span class="math"&gt;\(D=(1,3,1)\)&lt;/span&gt;, and &lt;span class="math"&gt;\(E=(-1,-1,-5)\)&lt;/span&gt;. Show that set &lt;span class="math"&gt;\([C, D, E]\)&lt;/span&gt; cannot be a basis of &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(b) Which vector in (a) you should change in order to obtain a basis of &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt;? &lt;/p&gt;
&lt;p&gt;(c) Now, change the vector and prove it is a basis of &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;3.The polynomial &lt;span class="math"&gt;\(P(x) = a_0 + a_1x + a_2x^2+ ... + a_nx^n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(a) Show that P(x) is a linear combination of some&amp;nbsp;monomials.&lt;/p&gt;
&lt;p&gt;(b) Can you find a basis for the polynomial vector space? If so, prove that they are indeed a basis for the&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;(c) What is the dimention of the polynomial vector&amp;nbsp;space?&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;4.Orthonormal basis is a special kind of basis. It requires all basis vectors to be orthogonal to each other and has length of&amp;nbsp;1.&lt;/p&gt;
&lt;p&gt;(a) Show that &lt;span class="math"&gt;\(set[(1,0,0),(0,1,0),(0,0,1)]\)&lt;/span&gt; is a orthonormal basis for &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(b) Find another orthonormal basis for &lt;span class="math"&gt;\(\mathbb{R}_3\)&lt;/span&gt; (Try not to use the vectors on the&amp;nbsp;axis)&lt;/p&gt;
&lt;hr /&gt;
&lt;h1 id="answer-sheet"&gt;Answer sheet&lt;a class="headerlink" href="#answer-sheet" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;1.Let &lt;span class="math"&gt;\(A\)&lt;/span&gt;, &lt;span class="math"&gt;\(B\)&lt;/span&gt; be two vectors in 2d real vector space &lt;span class="math"&gt;\(\mathbb{R}_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(a)If &lt;span class="math"&gt;\(A = (1,2)\)&lt;/span&gt; and &lt;span class="math"&gt;\(B = (1,4)\)&lt;/span&gt;, are they linear independent or not? If they are, can you write (4,4) as a linear combination of &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;(b) If &lt;span class="math"&gt;\(A = (x,y)\)&lt;/span&gt; and &lt;span class="math"&gt;\(B = (x,2y)\)&lt;/span&gt;, what &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; value will make &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt; linear&amp;nbsp;dependent?&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term='Chapter 3 Meaning of "Linear" in linear algebra'></category></entry><entry><title>4-1 Linear Transformation</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/4-1-linear-transformation" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/4-1-linear-transformation</id><summary type="html">&lt;p&gt;We are finally here! All the idea that we introduced earlier, is for this amazing idea in linear algebra: &lt;strong&gt;linear transformation&lt;/strong&gt;. And this idea will lead us to a powerful tool in linear algebra: the&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s jump right into the definition of linear transformation, and see what is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We are finally here! All the idea that we introduced earlier, is for this amazing idea in linear algebra: &lt;strong&gt;linear transformation&lt;/strong&gt;. And this idea will lead us to a powerful tool in linear algebra: the&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s jump right into the definition of linear transformation, and see what is the relationship between linear transformation and matrix&amp;nbsp;multiplication.&lt;/p&gt;
&lt;p&gt;The two key words are &amp;#8220;Linear&amp;#8221; and &amp;#8220;Transformation&amp;#8221;. We will began with the word transformation. In high school, transformation usually refer as the change from one graph to another graph. In here, the transformation can be understand as a function, a map that take in one vector and returns another one. The reason why we don&amp;#8217;t call it function is because we are interested in the &amp;#8220;movement&amp;#8221;. Just like you can visualize the graph being &amp;#8220;compressed&amp;#8221; or &amp;#8220;stretched&amp;#8221;. A linear transformation can be visualized as a vector &amp;#8220;moves&amp;#8221; to another&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;Notice that the transformation is not talking about only one vector being transformed into one vector. It is talking about every single vector that lives in the vector space being transformed into another vector. Like when we talk about the word &amp;#8220;function&amp;#8221;, we are not only interested in one x value change to a y value, we are interested in all x and y value in the domain and&amp;nbsp;range.&lt;/p&gt;
&lt;p&gt;But how about the word &amp;#8220;linear&amp;#8221;? Like what we learned before in &amp;#8220;linear&amp;#8221; combination, the word &amp;#8220;linear&amp;#8221; means this type of transformation follows certain rules: &lt;strong&gt;additivity&lt;/strong&gt; and &lt;strong&gt;homogeneity&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Additivity means that the transformation preserve&amp;nbsp;addition:&lt;/p&gt;
&lt;div class="math"&gt;$$f(\pmb{a}+\pmb{b}) = f(\pmb{a}) + f(\pmb{b})$$&lt;/div&gt;
&lt;p&gt;homogeneity, or more precisely, the homogeneity of degree 1 means the operation of scalar multiplication is&amp;nbsp;preserved.&lt;/p&gt;
&lt;div class="math"&gt;$$f(c\pmb{a}) = cf(\pmb{a})$$&lt;/div&gt;
&lt;p&gt;So what is so special about this type of transformation compare to&amp;nbsp;others?&lt;/p&gt;
&lt;p&gt;If you have any set of vector that forms a line, for example, all the vectors that has tips sitting on the x-axis. After the transformation, the vectors will still sitting on a line. So linear transformation will not &amp;#8220;curve&amp;#8221; the&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;Also, notice that these two condition also tells you a important detail, which is the zero vector stay as a zero vector. You can check that using the&amp;nbsp;condition.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s see a simple&amp;nbsp;example:&lt;/p&gt;
&lt;p&gt;The transformation we will see is the simplest transformation: the transformation of doing nothing at&amp;nbsp;all:&lt;/p&gt;
&lt;div class="math"&gt;$$f(\pmb{x}) = \pmb{x}$$&lt;/div&gt;
&lt;p&gt;Is this a linear transformation? Let&amp;#8217;s check additivity&amp;nbsp;first:&lt;/p&gt;
&lt;div class="math"&gt;$$f(\pmb{a}+\pmb{b}) = \pmb{a} + \pmb{b} $$&lt;/div&gt;
&lt;div class="math"&gt;$$f(\pmb{a}) + f(\pmb{b}) = \pmb{a} + \pmb{b}$$&lt;/div&gt;
&lt;div class="math"&gt;$$f(\pmb{a}+\pmb{b}) = f(\pmb{a}) + f(\pmb{b})$$&lt;/div&gt;
&lt;p&gt;Obviously, this follows the rule. Now let&amp;#8217;s check&amp;nbsp;homogeneity:&lt;/p&gt;
&lt;div class="math"&gt;$$f(c\pmb{a}) =c\pmb{a} = cf(\pmb{a})$$&lt;/div&gt;
&lt;p&gt;lovely! Both rules are satisfied. We can now say that the transformation of doing nothing is a linear&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;but that is way too boring, let&amp;#8217;s do a interesting one together: the transformation of rotating everything by 90 degrees counter&amp;nbsp;counterclockwise.&lt;/p&gt;
&lt;p&gt;To demonstrate the transformation. I will plot the sample vector and many other vectors during the transformation. To not make the graph too crowded, I will only draw the points where the tip of the vectors landed for other&amp;nbsp;vectors.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w4rotation" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;It seems impossible to show the additivity and homogeneity in this case. Unlike the last time, it is not easy to write down the &lt;span class="math"&gt;\(f(\pmb{x})\)&lt;/span&gt;. However, when you graph the transformation on the basis vectors of 2d space, things gets a lot&amp;nbsp;easier.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at how the basis vectors change under the transformation. More importantly, ask yourself whether if the basis is still a basis after the&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w4rotation" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4axis_rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see. the basis &lt;span class="math"&gt;\((1,0)\)&lt;/span&gt; and &lt;span class="math"&gt;\((0,1)\)&lt;/span&gt; changed to &lt;span class="math"&gt;\((0,1)\)&lt;/span&gt; and &lt;span class="math"&gt;\((-1,0)\)&lt;/span&gt;. And it looks like the new basis still works&amp;nbsp;well. &lt;/p&gt;
&lt;p&gt;so if our vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; has x component &lt;span class="math"&gt;\(a\)&lt;/span&gt; and y component &lt;span class="math"&gt;\(b\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{x} = a(1,0)+b(0,1)$$&lt;/div&gt;
&lt;p&gt;in our new basis, the coefficients &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; shouldn&amp;#8217;t&amp;nbsp;change:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{x}_{new} = a(0,1)+b(-1,0)$$&lt;/div&gt;
&lt;p&gt;Now we have enough information to show the rotation by 90 degrees is a linear transformation. You will show this in the&amp;nbsp;assignment.&lt;/p&gt;
&lt;p&gt;To see this geometrically, if you connect the points to form a grid. You will see that the lines remain as lines after the transformation. The space didn&amp;#8217;t&amp;nbsp;&amp;#8220;curve&amp;#8221;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 4 Transformation: the origin of matrix"></category></entry><entry><title>4-2 Matrix multiplication with vector</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/4-2-matrix-multiplication-with-vector" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/4-2-matrix-multiplication-with-vector</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Unfortunately, no one can told you what the Matrix is. You have to see it for&amp;nbsp;yourself. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For most of us, the first time when we hear the word &amp;#8220;Matrix&amp;#8221; is from the movie Matrix. So, here I quote one of the character in Matrix as the start of this …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Unfortunately, no one can told you what the Matrix is. You have to see it for&amp;nbsp;yourself. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For most of us, the first time when we hear the word &amp;#8220;Matrix&amp;#8221; is from the movie Matrix. So, here I quote one of the character in Matrix as the start of this chapter. To &amp;#8220;see&amp;#8221; what matrix really is, the knowledge of linear transformation is required. Good thing is, we have learned what linear transformation is,  so now is time to find a way to describe the transformation numerically. Hopefully, we can all &amp;#8220;see&amp;#8221; it by the end of the&amp;nbsp;section.&lt;/p&gt;
&lt;p&gt;We knew that the linear transformation is the transformation between vector space, and vector space can be expressed as the span of basis vector. So, to write down the linear transformation, we need to see how the basis vector changes under the&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s again take the example from the last section. The transformation of rotating 90 degrees counterclockwise. Remember last time we said the transformation act on the basis of space and change the basis to a new&amp;nbsp;one:&lt;/p&gt;
&lt;div class="math"&gt;$$(1,0) \rightarrow \color{red}{(0,1)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$(0,1) \rightarrow \color{red}{(-1,0)}$$&lt;/div&gt;
&lt;p&gt;Now let&amp;#8217;s introduce a better way to write down the vector. For a vector lives in 2d, we usually write them from up to down and close it with a square&amp;nbsp;bracket:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1\\
0
\end{bmatrix}\rightarrow\color{red}{\begin{bmatrix}
0\\
1
\end{bmatrix}}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
0\\
1
\end{bmatrix}\rightarrow\color{red}{\begin{bmatrix}
-1\\
0
\end{bmatrix}}$$&lt;/div&gt;
&lt;p&gt;Then, to describe the transformation, we just need to write down the two basis vectors side by side (you will see real soon why we do&amp;nbsp;this):&lt;/p&gt;
&lt;div class="math"&gt;$$T(\pmb{x}) = \color{red}{\begin{bmatrix}
0 &amp;amp; -1\\
1 &amp;amp; 0
\end{bmatrix}}$$&lt;/div&gt;
&lt;p&gt;To see why this notation even make sense, we will put this square thing next to a vector. Like functions, we can input a number and return another one, this transformation eat a vector and spit out another vector. In our case, the input vector is the vector before the transformation and the output is&amp;nbsp;after.&lt;/p&gt;
&lt;div class="math"&gt;$$T(\begin{bmatrix}
1\\
0
\end{bmatrix}) = \color{red}{\begin{bmatrix}
0 &amp;amp; -1\\
1 &amp;amp; 0
\end{bmatrix}}\begin{bmatrix}
1\\
0
\end{bmatrix} = \begin{bmatrix}
0\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So how did this calculating work? Let&amp;#8217;s take a close look at each&amp;nbsp;element. &lt;/p&gt;
&lt;p&gt;The vector (1,0) has 1 as x-component so the result has 1 portion of the first row(the new x basis). It also has 0 as its y-component so it has 0 portion of the second row(the new y basis). Notice this comes from the fact that the coefficients of linear combination don&amp;#8217;t change during the transformation. If you have one &lt;span class="math"&gt;\(\hat{x}\)&lt;/span&gt; and zero &lt;span class="math"&gt;\(\hat{y}\)&lt;/span&gt;, you remains one &lt;span class="math"&gt;\(\hat{x}\)&lt;/span&gt; and zero &lt;span class="math"&gt;\(\hat{y}\)&lt;/span&gt;. The only thing that change is the&amp;nbsp;basis.&lt;/p&gt;
&lt;div class="math"&gt;$$\color{red}{\begin{bmatrix}
0 &amp;amp; -1\\
1 &amp;amp; 0
\end{bmatrix}}\begin{bmatrix}
1\\
0
\end{bmatrix} = 1*\begin{bmatrix}
0\\
1
\end{bmatrix}+ 0 * \begin{bmatrix}
-1\\
0
\end{bmatrix} = {\begin{bmatrix}
0 + 0\\
1 + 0
\end{bmatrix}} = \begin{bmatrix}
0\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w4rotation" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4axis_rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;and as you see in the animation, the vector (1,0) indeed moves to&amp;nbsp;(0,1). &lt;/p&gt;
&lt;p&gt;So what if we want to transform something harder? let&amp;#8217;s rotate the vector&amp;nbsp;(a,b):&lt;/p&gt;
&lt;div class="math"&gt;$$T(\begin{bmatrix}
a\\
b
\end{bmatrix}) = \color{red}{\begin{bmatrix}
0 &amp;amp; -1\\
1 &amp;amp; 0
\end{bmatrix}}\begin{bmatrix}
a\\
b
\end{bmatrix} = a*\begin{bmatrix}
0\\
1
\end{bmatrix}+ b * \begin{bmatrix}
-1\\
0
\end{bmatrix} = {\begin{bmatrix}
0 + (-b)\\
a + 0
\end{bmatrix}} = \begin{bmatrix}
-b\\
a
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w4rotation" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;We can confirm this result is also true by looking at the&amp;nbsp;animation.&lt;/p&gt;
&lt;p&gt;As you already guessed it, the square thing is called matrix and this operation we did is called the matrix&amp;nbsp;multiplication. &lt;/p&gt;
&lt;p&gt;Anyone who learned the matrix multiplication before might find this operation slightly different from the way you learned before, because usually the matrix multiplication was introduced like&amp;nbsp;this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w4matrixwiki" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4matrix_multi.png" /&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t panic, you will soon find out the two ways are exactly the same. But imaging matrix multiplication as linear transformation of vectors is much much more intuitive than pure&amp;nbsp;algebra. &lt;/p&gt;
&lt;p&gt;Can we figure out more things from the matrix multiplication we&amp;nbsp;defined?&lt;/p&gt;
&lt;p&gt;First is the dimension of matrix. We can see that our transformation matrix has two rows and two columns, we call this matrix a &lt;strong&gt;2 by 2 matrix&lt;/strong&gt; or &lt;strong&gt;2x2 matrix&lt;/strong&gt;. In convention, we write the number of rows first and then the columns. So a 4 by 3 matrix will have 4 rows and 3&amp;nbsp;columns.&lt;/p&gt;
&lt;p&gt;But why do our matrix has such shape? Why not 10 by 10 or 20 by 20? The answer can be find from the dimension of the input vector and output vector. the transformation takes in a 2d vector and spit out another 2d vector so the dimension of matrix has to be 2 by 2. If the transformation takes in a 3d vector and returns a 2d vector, then the dimension of this transformation matrix has to be 2 by&amp;nbsp;3.&lt;/p&gt;
&lt;div class="math"&gt;$$T(\begin{bmatrix}
x\\
y\\
z
\end{bmatrix}) = \color{red}{\begin{bmatrix}
a &amp;amp; b &amp;amp; c\\
d &amp;amp; e &amp;amp; f
\end{bmatrix}}\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} = x*\begin{bmatrix}
a\\
d
\end{bmatrix}+ y * \begin{bmatrix}
b\\
e
\end{bmatrix}+ z * \begin{bmatrix}
c\\
f
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;There is also an interesting question to think about: Can any linear transformation be written as a matrix? If that so, then any matrix with any dimension can be treat as a linear&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Here is another thinking question: what if two matrix multiply each other? What is the result looks like? More importantly, what is the meaning of doing&amp;nbsp;that?&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 4 Transformation: the origin of matrix"></category></entry><entry><title>4-3 Assignment</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/4-3-assignment" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/4-3-assignment</id><summary type="html">&lt;ol&gt;
&lt;li&gt;In 4-1, we worked on the transformation that rotation 90 degree counterclockwise. In this practice, you will write down the transformation matrix for any rotation in 2d and prove that it is a linear&amp;nbsp;transformation.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li&gt;Consider a transformation matrix &lt;span class="math"&gt;\(T(\pmb{x}) R^2\rightarrow R^2\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$T(\pmb{x …&lt;/div&gt;</summary><content type="html">&lt;ol&gt;
&lt;li&gt;In 4-1, we worked on the transformation that rotation 90 degree counterclockwise. In this practice, you will write down the transformation matrix for any rotation in 2d and prove that it is a linear&amp;nbsp;transformation.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li&gt;Consider a transformation matrix &lt;span class="math"&gt;\(T(\pmb{x}) R^2\rightarrow R^2\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$T(\pmb{x}) = \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 2 
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;(1) What is this transformation does to the space, you can try to transform some vector to&amp;nbsp;see.&lt;/p&gt;
&lt;p&gt;(2) What kinds of vectors do not change directions after the&amp;nbsp;transformation?&lt;/p&gt;
&lt;p&gt;(3) If now the transformation matrix&amp;nbsp;became:&lt;/p&gt;
&lt;div class="math"&gt;$$T(\pmb{x}) = \begin{bmatrix}
1 &amp;amp; 1\\
0 &amp;amp; 2 
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;What kinds of vectors do not change directions after the transformation this time? Do we expect the same&amp;nbsp;answer?&lt;/p&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li&gt;Consider following transformation&amp;nbsp;matrix:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$T_1(\pmb{x}) = \begin{bmatrix}
2 &amp;amp; 0 &amp;amp; 3\\
0 &amp;amp; 2 &amp;amp; 2
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;(1) What is the dimension of vectors before and after the&amp;nbsp;transformation?&lt;/p&gt;
&lt;p&gt;(2) After such transformation, the space is then transformed by another&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$T_2(\pmb{x}) = \begin{bmatrix}
2 &amp;amp; 0 \\
0 &amp;amp; 2 \\
1 &amp;amp; 2
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;What is the dimension of vectors after this&amp;nbsp;transformation?&lt;/p&gt;
&lt;p&gt;(3)Now combine these two transformation into one transformation &lt;span class="math"&gt;\(T_3(\pmb{x})\)&lt;/span&gt; so&amp;nbsp;that:&lt;/p&gt;
&lt;div class="math"&gt;$$T_3(\pmb{x}) = T_2(T_1(\pmb{x}))$$&lt;/div&gt;
&lt;p&gt;Can you write &lt;span class="math"&gt;\(T_3(\pmb{x})\)&lt;/span&gt; down as a matrix? if so, what is the dimension of this matrix &lt;span class="math"&gt;\(T_3(\pmb{x})\)&lt;/span&gt;? (hint: Try to think matrix as columns of&amp;nbsp;vector)&lt;/p&gt;
&lt;p&gt;(4)What if you reverse the order of transformation? Say &lt;span class="math"&gt;\(T_4(\pmb{x}) = T_1(T_2(\pmb{x}))\)&lt;/span&gt;? Does that gives you the same transformation? What is the result tells&amp;nbsp;you?&lt;/p&gt;
&lt;h1 id="answer-sheet"&gt;Answer sheet&lt;a class="headerlink" href="#answer-sheet" title="Permanent link"&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 4 Transformation: the origin of matrix"></category></entry><entry><title>5-1 intercepts problem</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-1-intercepts-problem" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-1-intercepts-problem</id><summary type="html">&lt;p&gt;Historically, the matrix was not invented for linear transformation, but for a more practical problem: solving linear systems. In this unit, we are going to cover everything you need to know when solving a linear system. Then I will explain why it is better to solve them using&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Historically, the matrix was not invented for linear transformation, but for a more practical problem: solving linear systems. In this unit, we are going to cover everything you need to know when solving a linear system. Then I will explain why it is better to solve them using&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s start from the simplest linear system you can imagine: line&amp;nbsp;intercepts.&lt;/p&gt;
&lt;p&gt;Suppose we have two lines in Cartisian plane, line A and line&amp;nbsp;B:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5line_int.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here are their&amp;nbsp;equations:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{cases}
      2x-y\ =\ 2 &amp;amp; \text{Line A}\\
      x+y\ =\ 1 &amp;amp; \text{Line B}
    \end{cases}   
$$&lt;/div&gt;
&lt;p&gt;Now the classic questions are: where does these two lines meet? And do they meet at&amp;nbsp;all?&lt;/p&gt;
&lt;p&gt;It is fairly easy to see in graph that these two lines do intersect and they intersect at point (1,0). To solve this algebraically is also trivial, you can do a substitution and solve it under a&amp;nbsp;minute.&lt;/p&gt;
&lt;p&gt;If you can solve this, congratulation! You pass the grade 9 math exam! Clearly, this method is not a good way of solving system of linear equations. Why? I will give you two&amp;nbsp;reasons:&lt;/p&gt;
&lt;p&gt;First, how do we solve the question with more than 2&amp;nbsp;dimensions? &lt;/p&gt;
&lt;p&gt;Well, you might say we introduce more than two variables! a, b, c, d{static}. That is absurd because we only have 26 letters and if we use notation like &lt;span class="math"&gt;\(a_1, a_2\)&lt;/span&gt;, the equation will be not only long, but also nasty to&amp;nbsp;read.&lt;/p&gt;
&lt;p&gt;Second, how do we know if there is a&amp;nbsp;solution?&lt;/p&gt;
&lt;p&gt;Assume you are working on this 100 dimension linear system, it took you 3 days to realize that there is no solution! How frustrated is&amp;nbsp;that! &lt;/p&gt;
&lt;p&gt;So, Let&amp;#8217;s sum up. We need our new notation to have two things: One, It has to look good, precise, clear, and elegant. Two, it has to have a easy way to check whether there is a solution or&amp;nbsp;not.&lt;/p&gt;
&lt;p&gt;Luckily, we have matrix. The matrix notation solve the above questions perfectly and even gave us more details about the system. I will show you the way to write system of linear equations using&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s take the above equations as an&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{cases}
      2x-y\ =\ 2 &amp;amp; \text{Line A}\\
      x+y\ =\ 1 &amp;amp; \text{Line B}
    \end{cases}   
$$&lt;/div&gt;
&lt;p&gt;The left side of the equations are some variable with different coefficients, so let&amp;#8217;s start from&amp;nbsp;there.&lt;/p&gt;
&lt;p&gt;Instead of writing all the x and y in our equations, we can put all of them at the side as a&amp;nbsp;vector:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
x\\
y
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;then we can write only the coefficients in front of variables as a&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2&amp;amp;-1\\
1&amp;amp;1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;To get &lt;span class="math"&gt;\(2x-y\ =\ 2\)&lt;/span&gt; and &lt;span class="math"&gt;\(x+y\ =\ 1\)&lt;/span&gt; back, we can do a matrix&amp;nbsp;multiplication:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{cases}
      2x-y\ \\
      x+y\  
    \end{cases}   \rightarrow\begin{bmatrix}
2&amp;amp;-1\\
1&amp;amp;1
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;then we can rewrite the right hand side as a vector&amp;nbsp;too:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So we ended up with a matrix multiply on an unknown vector equals to a&amp;nbsp;vector:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{bmatrix}
2&amp;amp;-1\\
1&amp;amp;1
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}=\begin{bmatrix}
2\\
1
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;We can write this in a more abstract&amp;nbsp;form:&lt;/p&gt;
&lt;div class="math"&gt;$$\color{red}{A}\pmb{x} = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(\color{red}{A}\)&lt;/span&gt; is a matrix, &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; is the unknown vector that we are trying to solve and &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; is a&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;It is obvious to see that the matrix notation is way easier than the original one since you don&amp;#8217;t have to write down the variables over and over again. Moreover, it is much faster to do elimination. We will discuss the detail of Gauss elimination in the next&amp;nbsp;section.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>5-2 Gaussian elimination</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-2-gaussian-elimination" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-2-gaussian-elimination</id><summary type="html">&lt;p&gt;In this section we are going to learn the way to solve linear equations using Gaussian elimination. We are also going to introduced some special form of&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;So what is Gaussian elimination? In short, it is a algorithm that will &lt;strong&gt;Always&lt;/strong&gt; solve a linear system. If you follow the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this section we are going to learn the way to solve linear equations using Gaussian elimination. We are also going to introduced some special form of&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;So what is Gaussian elimination? In short, it is a algorithm that will &lt;strong&gt;Always&lt;/strong&gt; solve a linear system. If you follow the procedure, no matter how hard the linear systems are, you can solve it&amp;nbsp;guaranteed.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s go through a simple&amp;nbsp;example:
&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{cases}
      2x-y\ =\ 2  &amp;amp;\color{red}{(1)}\\
      x+y\ =\ 1 &amp;amp;\color{red}{(2)}
    \end{cases}   
$$&lt;/div&gt;
&lt;p&gt;We can write this in a matrix&amp;nbsp;form:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{bmatrix}
2&amp;amp;-1\\
1&amp;amp;1
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}=\begin{bmatrix}
2\\
1
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;To solve this as a high school student, you can try substitution or&amp;nbsp;elimination. &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s use elimination! You will first make a choice of eliminating x or y. It is much easier to eliminate y, all you need is to add first row to the second row and cancel out all the&amp;nbsp;y:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}+ \color{red}{(2)} \rightarrow 3x = 3 $$&lt;/div&gt;
&lt;div class="math"&gt;$$ x = 1 $$&lt;/div&gt;
&lt;p&gt;then we substitute the result back to &lt;span class="math"&gt;\((2)\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$1+y = 1$$&lt;/div&gt;
&lt;div class="math"&gt;$$y = 0 $$&lt;/div&gt;
&lt;p&gt;So how to do the same thing in matrix form? The first step we do is to make this linear equation &lt;span class="math"&gt;\(A\pmb{x} = \pmb{b}\)&lt;/span&gt; even easier. We will rewrite the equation to something we called &lt;strong&gt;Augmented matrix&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$  
\begin{bmatrix}
2&amp;amp;-1\\
1&amp;amp;1
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}=\begin{bmatrix}
2\\
1
\end{bmatrix}
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\downarrow
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    1 &amp;amp; 1  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;How do you &amp;#8220;read&amp;#8221; this notation? Well, think about the first column is the coefficients for x and the second column is the coefficients for y and the sum is given by the number after the&amp;nbsp;bar. &lt;/p&gt;
&lt;p&gt;We will see why this notation suit our purpose in a sec, now if we want to do the same thing as above, then how should we write&amp;nbsp;it?&lt;/p&gt;
&lt;p&gt;To write &lt;span class="math"&gt;\( \color{red}{(1)}+ \color{red}{(2)}\)&lt;/span&gt;, we can &lt;strong&gt;change&lt;/strong&gt; the row &lt;span class="math"&gt;\( \color{red}{(2)}\)&lt;/span&gt; to our new row &lt;span class="math"&gt;\( \color{red}{(1)}+ \color{red}{(2)}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(2)}\rightarrow \color{red}{(1)}+ \color{red}{(2)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    1\color{red}{+2} &amp;amp; 1\color{red}{-1}  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1\color{red}{+2}  
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    \color{red}{3} &amp;amp; \color{red}{0}  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      \color{red}{3}  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;this change is so called the &lt;strong&gt;row operation&lt;/strong&gt;, or &lt;strong&gt;elementary row operation&lt;/strong&gt;, There are in total three types of row operations. The first one is &lt;strong&gt;row addition&lt;/strong&gt;, which is exactly what we did above, replacing one row to this row adding another&amp;nbsp;row.&lt;/p&gt;
&lt;p&gt;then what we did is to divide the new row by 3, in order to get $ x = 1 $. we will perform the same operation&amp;nbsp;here:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(2)}\rightarrow \frac{1}{3} \times \color{red}{(2)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    3\color{red}{\div3} &amp;amp; 0\color{red}{\div3}  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      3\color{red}{\div3}  
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    \color{red}{1} &amp;amp; \color{red}{0}  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      \color{red}{1}  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;And this is our next type of row operation, called &lt;strong&gt;row multiplication&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Now comes to the hard part, which is our &amp;#8220;substitution&amp;#8221;. In grade 9, these two method: substitution and elimination were taught as different method. But in here, we can see that both method can be break down into numbers of basic row&amp;nbsp;operations.&lt;/p&gt;
&lt;p&gt;What we did after we figured out the x is we plugged into the original equation &lt;span class="math"&gt;\(\color{red}{(2)}\)&lt;/span&gt;. But as you see, we don&amp;#8217;t have the original equations anymore,, so we have to plug into the first one. How to do that? we can first remove all the x from the first equation by&amp;nbsp;doing:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}\rightarrow \color{red}{(1)} - 2 \times \color{red}{(2)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2\color{red}{-2} &amp;amp; -1  \\
    1 &amp;amp; 0  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2 \color{red}{-2} \\
      1 
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    \color{red}{0} &amp;amp; -1  \\
    1 &amp;amp; 0  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      \color{red}{0}  \\
      1  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Next we can divide the first row by &lt;span class="math"&gt;\(-1\)&lt;/span&gt; to get $y = $ something instead of  $-y = $&amp;nbsp;something:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}\rightarrow -1 \times\color{red}{(1)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    0 &amp;amp; -1\color{red}{\div-1}  \\
    1 &amp;amp; 0  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0\color{red}{\div-1} \\
      1 
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    0 &amp;amp; \color{red}{1}  \\
    1 &amp;amp; 0  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      \color{red}{0}  \\
      1  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Basically, our job is done here. However, for simplicity, we would like to show &lt;span class="math"&gt;\(x = 1\)&lt;/span&gt; first and then show &lt;span class="math"&gt;\(y = 0\)&lt;/span&gt;, so we can do the last type of row operation here, called the &lt;strong&gt;row switching&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}\leftrightarrow \color{red}{(2)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    0 &amp;amp; 1  \\
    1 &amp;amp; 0  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0 \\
      1 
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    1 &amp;amp; 0  \\
    0 &amp;amp; 1  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1  \\
      0  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Then, we can easily read the result just by looking at the&amp;nbsp;rows.&lt;/p&gt;
&lt;p&gt;Alright! We have learned the notation and row operation, now it is the time to find out how to perform the Gaussian elimination. This method is not always the optimum one when you solve linear system, but it is surely the one you can rely on when you have no clue how to&amp;nbsp;start.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s have a fairly simple example to show how this&amp;nbsp;work.&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    1 &amp;amp; 0 &amp;amp; 2  \\
    1 &amp;amp; 3 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1  \\
      3  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;As you can see, we have a system of equations with three unknowns. We started from the first row and we only care about the first number in the row. If this number is not &lt;span class="math"&gt;\(1\)&lt;/span&gt;, we will divide whatever this number is to make our first number to be &lt;span class="math"&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this case, we have that number already be &lt;span class="math"&gt;\(1\)&lt;/span&gt; so we moved on to next&amp;nbsp;step.&lt;/p&gt;
&lt;p&gt;The next step is to make the first number on the second row to be &lt;span class="math"&gt;\(0\)&lt;/span&gt;. To do that, you will do a row addition(subtraction). The only row we will use is the first row since the first row already has the coefficient of x to be &lt;span class="math"&gt;\(1\)&lt;/span&gt;, we just need to subtract as many row 1 as we want to get the first number on the second row to be &lt;span class="math"&gt;\(0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this case, the first number on the second row is 1, so we need to subtract exactly one row 1 to row&amp;nbsp;2:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(2)}\rightarrow  \color{red}{(2)}- \color{red}{(1)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    1 &amp;amp; 0 &amp;amp; 2  \\
    1 &amp;amp; 3 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1  \\
      3  \\
    \end{matrix}
  \right.
\right]\rightarrow \left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    1 &amp;amp; 3 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      3  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Now we do the similar thing as above, we check if the coefficient of the second number is &lt;span class="math"&gt;\(1\)&lt;/span&gt; or not, if not, we will do a division to make this number to be &lt;span class="math"&gt;\(1\)&lt;/span&gt;. Luckily, this time we get a &lt;span class="math"&gt;\(1\)&lt;/span&gt; again! So we don&amp;#8217;t have to do&amp;nbsp;anything.&lt;/p&gt;
&lt;p&gt;You might already see the pattern here. The next step is to make sure that on the third row, we have &lt;span class="math"&gt;\(0\)&lt;/span&gt; for both the first coefficient and the second one. To do that, we subtract different amount of row 1 and row&amp;nbsp;2.&lt;/p&gt;
&lt;p&gt;In our case, The first number for the third row is 1, which means that we need to subtract off one row&amp;nbsp;1:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(3)}\rightarrow  \color{red}{(3)}- \color{red}{(1)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    1 &amp;amp; 3 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      3  \\
    \end{matrix}
  \right.
\right]\rightarrow \left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 4 &amp;amp; 0
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      1  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Then we subtract out four row 2 since the second number of row 3 is now &lt;span class="math"&gt;\(4\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;You might find that we can also divide the new row 3 by 4 and we immediately get what y is. But as I mentioned before, the Gaussian elimination is not always the easiest one, so we will follow the more general&amp;nbsp;case.&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(3)}\rightarrow  \color{red}{(3)}- 4\times\color{red}{(2)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 4 &amp;amp; 0
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      1  \\
    \end{matrix}
  \right.
\right]\rightarrow \left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 0 &amp;amp; -4
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      5  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;we do the same thing again, now this time the leading coefficient is &lt;span class="math"&gt;\(-4\)&lt;/span&gt;, so we divide the row 3 by &lt;span class="math"&gt;\(-4\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(3)}\rightarrow  \color{red}{(3)}\div (-4) $$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 0 &amp;amp; -4
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      5  \\
    \end{matrix}
  \right.
\right]\rightarrow \left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 0 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      -5/4  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Lovely, we are half way there! As you can see, our matrix on the left now became a special shape with all diagonal term to be &lt;span class="math"&gt;\(1\)&lt;/span&gt; and the bottom left to be all zero. This type of matrix is what we called &lt;strong&gt;lower triangular matrix&lt;/strong&gt;, but that is not our topic today so we won&amp;#8217;t dig on too&amp;nbsp;much. &lt;/p&gt;
&lt;p&gt;The rest of the job is much easier than the first half, you will do the similar thing but work your way up this time. The goal is to have all diagonal terms to be &lt;span class="math"&gt;\(1\)&lt;/span&gt; and rest to be zero. To do that , we first subtract one row 3 to row 2 to get rid of that annoying &lt;span class="math"&gt;\(1\)&lt;/span&gt; at the end of row&amp;nbsp;2:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(2)}\rightarrow  \color{red}{(2)}- \color{red}{(3)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 1  \\
    0 &amp;amp; 0 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1  \\
      -5/4  \\
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 0  \\
    0 &amp;amp; 0 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1/4  \\
      -5/4  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Then we add one row 2 to row 1 and subtract one row 3 to row&amp;nbsp;1:&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}\rightarrow  \color{red}{(1)}+\color{red}{(2)}- \color{red}{(3)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; -1 &amp;amp; 1  \\
    0 &amp;amp; 1 &amp;amp; 0  \\
    0 &amp;amp; 0 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1/4  \\
      -5/4  \\
    \end{matrix}
  \right.
\right]\rightarrow\left[
  \begin{matrix}
    1&amp;amp; 0 &amp;amp; 0  \\
    0 &amp;amp; 1 &amp;amp; 0  \\
    0 &amp;amp; 0 &amp;amp; 1
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      7/2  \\
      1/4  \\
      -5/4  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;And we have our&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;Sadly, you are not always getting a great answer like this. Just like if you are solving two linear equations, you might experience something like two parallel lines or two same lines. When you solve a linear system, a non-trivial solution is not always&amp;nbsp;guaranteed.&lt;/p&gt;
&lt;p&gt;Sometimes, you might end up with something like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; 0 &amp;amp; 0  \\
    0 &amp;amp; 1 &amp;amp; 0  \\
    0 &amp;amp; 0 &amp;amp; 0
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0  \\
      0  \\
      1  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Or&amp;nbsp;this:&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1&amp;amp; 0 &amp;amp; 0  \\
    0 &amp;amp; 1 &amp;amp; 0  \\
    0 &amp;amp; 0 &amp;amp; 0
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0  \\
      0  \\
      0  \\
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Don&amp;#8217;t worry! You will see these cases in the practice. We are not going to discuss these case in&amp;nbsp;detail. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>5-3 Column space and null space</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-3-column-space-and-null-space" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-3-column-space-and-null-space</id><summary type="html">&lt;p&gt;As we discussed at the beginning of this chapter, We want our new notation to be much better than the old one in two aspects. The first one: Simplicity, is done by writing the equations into matrix. Now comes to the second one, which is to know how many solutions …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As we discussed at the beginning of this chapter, We want our new notation to be much better than the old one in two aspects. The first one: Simplicity, is done by writing the equations into matrix. Now comes to the second one, which is to know how many solutions are there before we solve the&amp;nbsp;equations.&lt;/p&gt;
&lt;p&gt;This sounds great, but how should we do this? Let&amp;#8217;s start from 2d and then move on to higher&amp;nbsp;dimension.&lt;/p&gt;
&lt;p&gt;Our linear equations on plane looks like just lines. So solving linear equations means you want to find the certain spot where two of your equations are satisfied simultaneously. In another word, the point (solution) has to be on both&amp;nbsp;lines.&lt;/p&gt;
&lt;p&gt;So what are the&amp;nbsp;cases?&lt;/p&gt;
&lt;p&gt;The first case is obvious, two lines intersect at one point. In this case, we have exactly &lt;strong&gt;one&lt;/strong&gt;&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5line_int.png" /&gt;&lt;/p&gt;
&lt;p&gt;The second case is two parallel lines. In this case, we have &lt;strong&gt;zero&lt;/strong&gt;&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5line_para.png" /&gt;&lt;/p&gt;
&lt;p&gt;The third case is less obvious, you can place your two lines at the same place. In this case, all the points on these lines are the solution. We can say there are &lt;strong&gt;infinite&lt;/strong&gt;&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5same_line.gif" /&gt;&lt;/p&gt;
&lt;p&gt;I personally don&amp;#8217;t like to say there are infinite many solution. Here is the reason: Saying infinite solutions is not useful, at least in some cases. For example, there are infinite many points on one line, but there are also infinite many points on two lines, a plane, a little triangle, or a cube. So only saying &amp;#8220;there are infinite many solutions&amp;#8221; won&amp;#8217;t give you enough&amp;nbsp;information. &lt;/p&gt;
&lt;p&gt;If we write these three different cases in augment matrix, you will see that the second one and the third one are very&amp;nbsp;special:&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    2 &amp;amp; -1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1 
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    2 &amp;amp; -1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0  \\
      0 
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Both cases has two &lt;strong&gt;linearly dependent&lt;/strong&gt; rows, but the vectors on the right are different. Let&amp;#8217;s look at them one by&amp;nbsp;one:&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    2 &amp;amp; -1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      -1 
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;This one is saying that &lt;span class="math"&gt;\(2x-y = 2\)&lt;/span&gt; and also &lt;span class="math"&gt;\(2x-y = -1\)&lt;/span&gt;. Obviously this will end up with no solution since you can combine them and give you &lt;span class="math"&gt;\(2 = -1\)&lt;/span&gt;. For this type of linear system, we say they are &lt;strong&gt;inconsistent&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Then let&amp;#8217;s look at the next&amp;nbsp;one:&lt;/p&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    2 &amp;amp; -1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      0 \\
      0
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;This one is ridiculous. The two equations are literally the same thing! So it didn&amp;#8217;t tell us enough information about the system! Of course you are getting infinite many solution because you have two variable with only one&amp;nbsp;equation.&lt;/p&gt;
&lt;p&gt;So Let&amp;#8217;s sum up here. If the matrix has linear dependent rows, then it means that at least one of the row is &amp;#8220;useless&amp;#8221;. So if you have a n by n matrix and one of the row is telling the same thing as other rows, then you will not have sufficient condition to solve this system. Then you will end up with many&amp;nbsp;solutions. &lt;/p&gt;
&lt;p&gt;If your matrix has linear dependent rows and the vector don&amp;#8217;t match, then it means you have parallel lines&amp;amp;planes. Then you end up with no&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;Then finally, if all your rows are linear independent, congratulation! You can have a non-trivial&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;But why linear independent rows can give you non-trivial solution? Let&amp;#8217;s see if we can understand it using the knowledge of linear&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;The equation we are going to solve is&amp;nbsp;this:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{\color{red}x} = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Solving this equation means to find the vector &lt;span class="math"&gt;\(\pmb{\color{red}x}\)&lt;/span&gt; such that after the transformation it became &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;By look at the transformation, we can predict what will happen if we put a vector in there. Let&amp;#8217;s start with a linear dependent&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp;-1\\
2 &amp;amp;-1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So what is the transformation looks&amp;nbsp;like?&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5linear_trans.gif" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, all the vectors are transformed onto a line &lt;span class="math"&gt;\(y = x\)&lt;/span&gt;. This makes sense since the transformation returns exactly same number for x and y. In fact, any linear dependent 2 by 2 matrix will squish the 2d plane to a line(or a point if everything is zero). So, if we are looking for a specific &lt;span class="math"&gt;\(\pmb{\color{red}x}\)&lt;/span&gt; that gives you &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;. Then there are two possible results: One is that your &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; actually landed on this line so you get some solution. The other case is your &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; is unfortunately not on this line so the system is inconsistent, no such &lt;span class="math"&gt;\(\pmb{\color{red}x}\)&lt;/span&gt; can give you that &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; vector after the&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Now why do you have multiple solutions for one &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;? Well, If we just look at the transformation itself, I looks like all the vectors in 2d space are &lt;strong&gt;projected&lt;/strong&gt; on the 1d line. Like the shadow under sun. So it kind of makes sense if different objects returns exactly same&amp;nbsp;shadow.&lt;/p&gt;
&lt;p&gt;But this is only 2 dimension. What if we have more than 2? what if we have dimension of 10? how do we understand the transformation that happens in 100 dimension? Obviously we need more tools to do that. So, let&amp;#8217;s use the knowledge of span and basis&amp;nbsp;vector!&lt;/p&gt;
&lt;p&gt;We know that we can think of any matrices as linear transformation, and each column in a transformation matrix tells us how basis vector transform. So why don&amp;#8217;t we find the span of those basis vectors after the transformation? That will definitely give us some information about this&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s take the above matrix as a&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp;-1\\
2 &amp;amp;-1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The column vectors&amp;nbsp;are:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2\\
2
\end{bmatrix},\begin{bmatrix}
-1\\
-1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So the span of those vectors give us the &lt;span class="math"&gt;\(y = x\)&lt;/span&gt; line on 2d&amp;nbsp;plane. &lt;/p&gt;
&lt;p&gt;What do we know from this? We know that any vectors after this transformation will end up sitting on the line &lt;span class="math"&gt;\(y = x\)&lt;/span&gt;. Why? Well any vector on the plane can be rewrite into a linear combination of the basis&amp;nbsp;vector:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
a\\
b
\end{bmatrix} = a\begin{bmatrix}
1\\
0
\end{bmatrix}+ b\begin{bmatrix}
0\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Then if we apply the&amp;nbsp;transformation:&lt;/p&gt;
&lt;div class="math"&gt;$$T\begin{bmatrix}
a\\
b
\end{bmatrix} = a \times T\begin{bmatrix}
1\\
0
\end{bmatrix}+ b \times T\begin{bmatrix}
0\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So the vector after the transformation will be a linear combination of the column vectors &lt;span class="math"&gt;\(T&lt;div class="math"&gt;\begin{bmatrix}
1\\
0
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and &lt;span class="math"&gt;\(T&lt;div class="math"&gt;\begin{bmatrix}
0\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. Therefore, the vector after the transformation will for sure sit on the span of column vectors, because the span is the collection of all possible linear&amp;nbsp;combinations.&lt;/p&gt;
&lt;p&gt;Do that span of column vectors has a name? Yes, it is called &lt;strong&gt;Column space&lt;/strong&gt;. By looking at the column space, we will know where our vectors live after the transformation. It is just like the idea of range in&amp;nbsp;function.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at the dimension of column space. For a n by n matrix, which means you have n variable and n equations(or you can think of a dimension n vector transform to a same dimension vector). We can say the dimension of matrix is n. if its column space also have dimension of n, what does this tell us? Well, it means your vector after the transformation lives in the same dimension n space. In the other word, the columns are linearly independent. Later on we will know that this also means the rows are linearly independent&amp;nbsp;too. &lt;/p&gt;
&lt;p&gt;Here is the tricky part. What if the dimension is less than n? You might say: Sure! Then it means the linear system has no solution or many solution. But I want to know more about&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;An interesting question to ask is: We start with dimension of n, we ended up with dimension of something less than n, so where does this &amp;#8220;missing&amp;#8221; dimension go? Let&amp;#8217;s look at the equation&amp;nbsp;again:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{\color{red}x} = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Assume we have linear independent columns (or you can say we have only one solution). Let&amp;#8217;s call the solution &lt;span class="math"&gt;\(\pmb{x}_1\)&lt;/span&gt;,&amp;nbsp;so:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x}_1 = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Now let&amp;#8217;s consider the similar&amp;nbsp;equation:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \pmb{0}$$&lt;/div&gt;
&lt;p&gt;if there is some non-zero &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; satisfy this equation, we are in a big trouble.&amp;nbsp;Why?&lt;/p&gt;
&lt;p&gt;Assume that &lt;span class="math"&gt;\(A\pmb{x}_2 = \pmb{0}\)&lt;/span&gt; for some non-zero &lt;span class="math"&gt;\(\pmb{x}_2\)&lt;/span&gt;, the I can say there exist a brand new solution for &lt;span class="math"&gt;\(A\pmb{x} = \pmb{b}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x}_1 + A\pmb{x}_2 = \pmb{b} + \pmb{0} $$&lt;/div&gt;
&lt;div class="math"&gt;$$A(\pmb{x}_1 + \pmb{x}_2) = \pmb{b} $$&lt;/div&gt;
&lt;p&gt;The new solution is &lt;span class="math"&gt;\(\pmb{x}_1 + \pmb{x}_2\)&lt;/span&gt;. For linear independent matrix, this $\pmb{x}_2 $ has to be zero, other wise you won&amp;#8217;t get only one&amp;nbsp;solution. &lt;/p&gt;
&lt;p&gt;What if the rows are linear dependent? Then the equation &lt;span class="math"&gt;\(A\pmb{x} = \pmb{0}\)&lt;/span&gt; will have non-zero&amp;nbsp;solution! &lt;/p&gt;
&lt;p&gt;Take the same matrix as example, if we solve &lt;span class="math"&gt;\(A\pmb{x} = \pmb{0}\)&lt;/span&gt; for this matrix we will&amp;nbsp;have:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp;-1\\
2 &amp;amp;-1
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix} = \begin{bmatrix}
0\\
0
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;This equation is easy to solve, we just have&amp;nbsp;:&lt;/p&gt;
&lt;div class="math"&gt;$$ 2x-y = 0 $$&lt;/div&gt;
&lt;p&gt;All the vectors on the line $ y = 2x $ satisify the equations. We can also write the result&amp;nbsp;as:&lt;/p&gt;
&lt;div class="math"&gt;$$span \left( \begin{bmatrix}
1\\
2
\end{bmatrix} \right) $$&lt;/div&gt;
&lt;p&gt;We actually have name for this space, we call it &lt;strong&gt;null space&lt;/strong&gt; or &lt;strong&gt;Kernel&lt;/strong&gt;. &amp;#8220;Null&amp;#8221; means &amp;#8220;nothing&amp;#8221;, Of course this does not means there is nothing in the space. It means the collection of all vectors that are transformed to &amp;#8220;nothing&amp;#8221;, the zero&amp;nbsp;vector.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s take a look at what null space is. Here I graphed a vector in 2d and drew some other vectors that are the linear combination of null space vector and the original vector. Notice in our case, all such vector sits on a line since our null space is one&amp;nbsp;dimensional.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5nullspace.gif" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, all the vectors were transformed into one same vector as we expected. if we know one solution of the linear system, adding any null space vector to that solution will give you a new solution. So if the null space of your matrix is not zero, then once you have a solution(if the system is consistent), you can get infinite many solution from adding the null space vectors. But if the null space of your matrix is zero, you will just get a unique&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;By checking the column space and the null space of a linear system, it is fairly easy to tell if the system has solution or not. Notice that we are no longer focusing on a single linear system. We are now treating the matrix as a linear transformation and focusing on how the whole space change. The linear equations only describes one result of this linear transformation. Once you understand this, it is much easier for you to understand why people are interested in linear&amp;nbsp;algebra.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>5-4 The cheat: inverse matrix</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-4-the-cheat-inverse-matrix" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-4-the-cheat-inverse-matrix</id><summary type="html">&lt;p&gt;Last time, we focused on the matrix in linear system. By treating the linear equations as transformation of vectors, we can easily predict the numbers of solution. But when we tried to solve the system, we still have to do elimination. So, can we do&amp;nbsp;better?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last time, we focused on the matrix in linear system. By treating the linear equations as transformation of vectors, we can easily predict the numbers of solution. But when we tried to solve the system, we still have to do elimination. So, can we do&amp;nbsp;better?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at our equation in matrix&amp;nbsp;form:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{\color{red}x} = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;The thing we are trying to solve is &lt;span class="math"&gt;\(\pmb{\color{red}x}\)&lt;/span&gt;, and we know the transformation &lt;span class="math"&gt;\(A\)&lt;/span&gt; and the target vector &lt;span class="math"&gt;\(b\)&lt;/span&gt;. Assume you solved the equation and you have exactly one solution, you know that the null space of this transformation is zero. In another word, the system will always give you a unique &lt;span class="math"&gt;\( \pmb{\color{red}x}\)&lt;/span&gt; for any vector &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;. But the problem is, when we change the vector &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;, we have to solve the system again, and that is not good for&amp;nbsp;us.&lt;/p&gt;
&lt;p&gt;So, is there a better way to solve&amp;nbsp;this? &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at the simplest equation that we all learned in elementary&amp;nbsp;school:&lt;/p&gt;
&lt;div class="math"&gt;$$a\color{red}x = b$$&lt;/div&gt;
&lt;p&gt;Notice that &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; are just number. To solve x, we just divide the &lt;span class="math"&gt;\(a\)&lt;/span&gt; both side. Good thing about this is that no matter how b change, we &lt;strong&gt;always&lt;/strong&gt; divide the number &lt;span class="math"&gt;\(a\)&lt;/span&gt; to get our solution for &lt;span class="math"&gt;\(\color{red}x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But wait a second, we don&amp;#8217;t have division in matrix! Obviously you can&amp;#8217;t divide matrices, it doesn&amp;#8217;t make any sense! Or is&amp;nbsp;it?&lt;/p&gt;
&lt;p&gt;The matrix act as a transformation &amp;#8220;function&amp;#8221;, like &lt;span class="math"&gt;\( y = sin(x)\)&lt;/span&gt;, you can&amp;#8217;t just divide functions. But, we can change our &amp;#8220;division&amp;#8221; into the multiplication of the reciprocal! What is the &amp;#8220;reciprocal&amp;#8221; of a function? Well, it is called the inverse of&amp;nbsp;function:&lt;/p&gt;
&lt;div class="math"&gt;$$f^{-1}(f(x)) = x$$&lt;/div&gt;
&lt;p&gt;So how do we solve the equation? Let&amp;#8217;s first see how we did it in&amp;nbsp;function:&lt;/p&gt;
&lt;div class="math"&gt;$$f(x) = b $$&lt;/div&gt;
&lt;div class="math"&gt;$$f^{-1}(f(x)) = f^{-1}(b) = x $$&lt;/div&gt;
&lt;div class="math"&gt;$$x = f^{-1}(b) $$&lt;/div&gt;
&lt;p&gt;Assume there exist the &amp;#8220;inverse&amp;#8221; of matrix, we can perform the same thing as we did in&amp;nbsp;function:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{\color{red}x} = \pmb{b}$$&lt;/div&gt;
&lt;div class="math"&gt;$$A^{-1}(A\pmb{\color{red}x}) = A^{-1}b = \color{red}x $$&lt;/div&gt;
&lt;div class="math"&gt;$$x = A^{-1}(b) $$&lt;/div&gt;
&lt;p&gt;So what has to be true for this &amp;#8220;inverse&amp;#8221; in order to make the above idea&amp;nbsp;practical?&lt;/p&gt;
&lt;p&gt;It is not hard to see that the second line has to be the definition for inverse&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$A^{-1}(A\pmb{\color{red}x}) = \color{red}x $$&lt;/div&gt;
&lt;p&gt;If you treat the two matrix &lt;span class="math"&gt;\(A^{-1}A\)&lt;/span&gt; as one matrix, Let&amp;#8217;s call it &lt;span class="math"&gt;\(I\)&lt;/span&gt; ,what is &lt;span class="math"&gt;\(I\)&lt;/span&gt; transformation looks&amp;nbsp;like?&lt;/p&gt;
&lt;div class="math"&gt;$$A^{-1}A = I$$&lt;/div&gt;
&lt;div class="math"&gt;$$(A^{-1}A)\pmb{\color{red}x} = \color{red}x $$&lt;/div&gt;
&lt;div class="math"&gt;$$I\pmb{\color{red}x} = \pmb{\color{red}x}$$&lt;/div&gt;
&lt;p&gt;Well, this matrix has to transform vector &lt;span class="math"&gt;\({\color{red}x}\)&lt;/span&gt; into itself. Such transformation is called &lt;strong&gt;identity matrix&lt;/strong&gt;. Let&amp;#8217;s construct the identity matrix&amp;nbsp;together.&lt;/p&gt;
&lt;p&gt;First, what is the dimension of this matrix? If the vector has to transform to itself, then the matrix must have size of n by n, where n is the dimension of that vector. How about the entries? The basis of this transformation should remain the&amp;nbsp;same:&lt;/p&gt;
&lt;div class="math"&gt;$$\left( \begin{bmatrix}
1\\
0\\
0\\
\vdots
\end{bmatrix} , \begin{bmatrix}
0\\
1\\
0\\
\vdots
\end{bmatrix} , \begin{bmatrix}
0\\
0\\
1\\
\vdots
\end{bmatrix} {static}. \right)$$&lt;/div&gt;
&lt;p&gt;For example, a 3 by 3 identity matrix should looks like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 1 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now we know what matrix are we looking for, it is time to see how to compute the inverse&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Our goal is to find a matrix &lt;span class="math"&gt;\(A^{-1}\)&lt;/span&gt;such that &lt;span class="math"&gt;\(A^{-1}A = I\)&lt;/span&gt;, Here we will introduce one of the methods to compute the inverse. For now, let&amp;#8217;s accept the fact that this method works. Later on, we will find out why this method&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;The method we will use is  Gauss–Jordan elimination, a variation of the classic Gaussian elimination. Let&amp;#8217;s say we want to find the inverse matrix of following matrix&amp;nbsp;A:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;First, we have to take a look at the matrix, because not all matrices have inverse. There are two things we need to check: First is the size of this matrix, it has to be a &lt;strong&gt;square matrix&lt;/strong&gt; (2 by 2, 3 by 3 etc.). Second, it has to have linear independent rows. Or use the concepts we learned earlier, for a n by n matrix, the dimension of column space has to be&amp;nbsp;n.&lt;/p&gt;
&lt;p&gt;For this easy example, we can see that both conditions are satisfied. So we know that this matrix has inverse, and now we can compute&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;First step is to write a augmented matrix by combining the matrix A and the identity matrix with the same&amp;nbsp;size:&lt;/p&gt;
&lt;div class="math"&gt;$$
[A|I] = \left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    3 &amp;amp; 4  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      0 &amp;amp; 1 
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Then we do Gaussian elimination. The goal is to make the left part of the augmented matrix to be identity matrix so the right part, which is the identity matrix at the beginning, will became the inverse&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s get&amp;nbsp;started:&lt;/p&gt;
&lt;div class="math"&gt;$$r_2 \rightarrow r_2-3r_1$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    3 &amp;amp; 4  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      0 &amp;amp; 1 
    \end{matrix}
  \right.
\right] \rightarrow \left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    0 &amp;amp; -2  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      -3 &amp;amp; 1 
    \end{matrix}
  \right.
\right] 
$$&lt;/div&gt;
&lt;div class="math"&gt;$$r_2 \rightarrow -\frac{1}{2}r_2$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    0 &amp;amp; -2  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      -3 &amp;amp; 1 
    \end{matrix}
  \right.
\right] \rightarrow \left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    0 &amp;amp; 1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      \frac{3}{2} &amp;amp; -\frac{1}{2}
    \end{matrix}
  \right.
\right] 
$$&lt;/div&gt;
&lt;div class="math"&gt;$$r_1 \rightarrow r_1 - 2r_2$$&lt;/div&gt;
&lt;div class="math"&gt;$$\left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    0 &amp;amp; 1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      \frac{3}{2} &amp;amp; -\frac{1}{2}
    \end{matrix}
  \right.
\right] \rightarrow \left[
  \begin{matrix}
    1 &amp;amp; 0  \\
    0 &amp;amp; 1 
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      -2 &amp;amp; 1 \\
      \frac{3}{2} &amp;amp; -\frac{1}{2}
    \end{matrix}
  \right.
\right] 
$$&lt;/div&gt;
&lt;p&gt;So the inverse of matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;&amp;nbsp;is:&lt;/p&gt;
&lt;div class="math"&gt;$$A^{-1} = \begin{bmatrix}
      -2 &amp;amp; 1 \\
      \frac{3}{2} &amp;amp; -\frac{1}{2}
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;We can check it by multiplying &lt;span class="math"&gt;\(A^{-1}\)&lt;/span&gt; and &lt;span class="math"&gt;\(A\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$A^{-1}A = \begin{bmatrix}
      -2 &amp;amp; 1 \\
      \frac{3}{2} &amp;amp; -\frac{1}{2}
\end{bmatrix}\begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;For 3 by 3 or higher dimension matrix, finding inverse can be really tedious. There are other ways to compute the inverse of a matrix, but if you do it by hand, Gaussian elimination is the most efficient&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;Now we successfully find the inverse of our matrix, we can finally find the nontrivial solution for our equation &lt;span class="math"&gt;\(A\pmb{\color{red}x} = \pmb{b}\)&lt;/span&gt; for any &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; we&amp;nbsp;want.&lt;/p&gt;
&lt;p&gt;But you might want to ask this question: There are cases that we don&amp;#8217;t get any solution or get infinite many solution, so if our solution is given by a simple&amp;nbsp;multiplication:&lt;/p&gt;
&lt;div class="math"&gt;$$\color{red}x = A^{-1} \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Then how can there be infinite many solution or no solution? An easy answer to this question is: For those cases, we couldn&amp;#8217;t find any&amp;nbsp;inverse. &lt;/p&gt;
&lt;p&gt;To see that, we have to treat the inverse matrix as a linear transformation. Not all matrices have inverse, for example, any matrix has different numbers of rows and columns cannot have&amp;nbsp;inverse.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at a specific&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$AB = \begin{bmatrix}
1 &amp;amp; 2 &amp;amp; 1\\
0 &amp;amp; 1 &amp;amp; 1
\end{bmatrix}\begin{bmatrix}
      1 &amp;amp; 0 \\
      0 &amp;amp; -1 \\
      0 &amp;amp; 2
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Apparently, the matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt; multiply by matrix &lt;span class="math"&gt;\(B\)&lt;/span&gt; give you identity matrix, but can you say that the inverse of &lt;span class="math"&gt;\(B\)&lt;/span&gt; is &lt;span class="math"&gt;\(A\)&lt;/span&gt;? Sort of, but not quite. We can call them &lt;strong&gt;left inverse&lt;/strong&gt; or &lt;strong&gt;right inverse&lt;/strong&gt;. To be a inverse matrix, multiply from left to right or right to left has to returns the same identity&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;For the above example, we can easily see&amp;nbsp;that:&lt;/p&gt;
&lt;div class="math"&gt;$$BA =\begin{bmatrix}
      1 &amp;amp; 0 \\
      0 &amp;amp; -1 \\
      0 &amp;amp; 2
\end{bmatrix} \begin{bmatrix}
1 &amp;amp; 2 &amp;amp; 1\\
0 &amp;amp; 1 &amp;amp; 1
\end{bmatrix} \neq \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;How about the matrix that transform 2d space to 1d&amp;nbsp;line? &lt;/p&gt;
&lt;div class="math"&gt;$$ A = \begin{bmatrix}
2 &amp;amp; -1\\
2 &amp;amp; -1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5linear_trans.gif" /&gt;&lt;/p&gt;
&lt;p&gt;Do they have inverse? Again, no. The inverse matrix is like the reverse operation of the previous transformation. If the transformation maps the plane to line, the reverse operation must transform a line to a plane. Which means that for a single vector on the line, it has to transform to many different vector on the&amp;nbsp;plane.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w5line_int" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w5inverse.gif" /&gt;&lt;/p&gt;
&lt;p&gt;That is not a linear transformation can do. It&amp;#8217;s like functions, for one x value, you can only get one y value. So for one vector input, you can only get one vector&amp;nbsp;output.&lt;/p&gt;
&lt;p&gt;In practice, we will see that finding the inverse in order to solve linear system is actually not very convenient. Nowadays, computer use other methods like &lt;strong&gt;&lt;span class="caps"&gt;LU&lt;/span&gt; decomposition&lt;/strong&gt;, which is so much faster than finding the inverse. Nevertheless, to have a unique solution, having inverse matrix is a&amp;nbsp;must.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>5-5 The fundamental theorem of Linear Algebra</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-5-the-fundamental-theorem-of-linear-algebra" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-5-the-fundamental-theorem-of-linear-algebra</id><summary type="html">&lt;p&gt;In this chapter, we learned quite a lot of practical concepts like solving linear system or inverse matrix. Now we can finally learn something more abstract and beautiful(in my opinion), which is the fundamental theorem of linear algebra. In here, we are just going to learn the first part …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this chapter, we learned quite a lot of practical concepts like solving linear system or inverse matrix. Now we can finally learn something more abstract and beautiful(in my opinion), which is the fundamental theorem of linear algebra. In here, we are just going to learn the first part of it which also called Rank–Nullity&amp;nbsp;theorem.&lt;/p&gt;
&lt;p&gt;The name of this theorem is actually not universal. It is popularized by one of my favorite professors: &lt;a href="http://www-math.mit.edu/~gs/"&gt;Gilbert Strang&lt;/a&gt;. This name is related to the famous theorem in calculus, the fundamental theorem of Calculus. The theorem itself is not hard to prove, so if you are interested, you can try to do it. But before we dig in to the theorem, we will quickly introduce two more&amp;nbsp;concepts.&lt;/p&gt;
&lt;p&gt;The first one is the &lt;strong&gt;Rank&lt;/strong&gt; of a matrix &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; transformation. The Rank of a matrix is defined as the dimension of its column space. For&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The Column space is the span of its columns. In this case, we have &lt;span class="math"&gt;\(span \left( &lt;div class="math"&gt;\begin{bmatrix}
1\\
3
\end{bmatrix}&lt;/div&gt;, &lt;div class="math"&gt;\begin{bmatrix}
2\\
4
\end{bmatrix}&lt;/div&gt; \right)\)&lt;/span&gt;, the two column vectors are linear independent so they span the entire 2d space. Then the dimension of its column space is 2. So we can&amp;nbsp;say:&lt;/p&gt;
&lt;div class="math"&gt;$$Rank(A) = 2$$&lt;/div&gt;
&lt;p&gt;The second one is the &lt;strong&gt;Nullity&lt;/strong&gt; of a matrix &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; transformation. The Nullity of a matrix is defined as the dimension of its null space or Kernel. For&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
2 &amp;amp; 1\\
2 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The null space of this transformation can be found by calculate the following&amp;nbsp;equation:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \pmb{0}$$&lt;/div&gt;
&lt;p&gt;if you solve this equation, you will find that the solution for &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; is &lt;span class="math"&gt;\(span \left( &lt;div class="math"&gt;\begin{bmatrix}
1\\
-2
\end{bmatrix}&lt;/div&gt;\right)\)&lt;/span&gt;, so the dimension of null space is 1, therefore we can&amp;nbsp;say:&lt;/p&gt;
&lt;div class="math"&gt;$$Nullity(A) = 1$$&lt;/div&gt;
&lt;p&gt;Now we finished our appetizer, let&amp;#8217;s check our main course. And of course, To understand the theorem better, we have to put this in the frame of linear&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s say we have a transformation matrix &lt;span class="math"&gt;\(T\)&lt;/span&gt;. This matrix transform all vectors in vector space &lt;span class="math"&gt;\(V\)&lt;/span&gt; to another vector space &lt;span class="math"&gt;\(W\)&lt;/span&gt;. So if you pick any vector in &lt;span class="math"&gt;\(W\)&lt;/span&gt;, say &lt;span class="math"&gt;\(\pmb{w} \in W\)&lt;/span&gt;. Then their must be at least one vector &lt;span class="math"&gt;\(\pmb{v}\)&lt;/span&gt; in vector space &lt;span class="math"&gt;\(V\)&lt;/span&gt;, such&amp;nbsp;that: &lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{w} = T(\pmb{v})$$&lt;/div&gt;
&lt;p&gt;What we are interested is the dimension. So what is the dimension of &lt;span class="math"&gt;\(V\)&lt;/span&gt;? This is easy. If your matrix &lt;span class="math"&gt;\(T\)&lt;/span&gt; is a &lt;span class="math"&gt;\(m \times n\)&lt;/span&gt; matrix, it means you take the vector with dimension &lt;span class="math"&gt;\(n\)&lt;/span&gt; and you output a vector with dimension &lt;span class="math"&gt;\(m\)&lt;/span&gt;. So, the input vector space must have dimension of &lt;span class="math"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;How about the dimension of &lt;span class="math"&gt;\(W\)&lt;/span&gt;? The vector space &lt;span class="math"&gt;\(W\)&lt;/span&gt; has a more complicated situation. You might think, like how we get the dimension of &lt;span class="math"&gt;\(V\)&lt;/span&gt;, the dimension of &lt;span class="math"&gt;\(W\)&lt;/span&gt; is simply &lt;span class="math"&gt;\(m\)&lt;/span&gt;. That is not true. For&amp;nbsp;example:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
0 &amp;amp; 0\\
0 &amp;amp; 0
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;This zero matrix returns only vector zero, which means our &lt;span class="math"&gt;\(W\)&lt;/span&gt; space has dimension of zero. But &lt;span class="math"&gt;\(m\)&lt;/span&gt; in this case is 2 so not true at&amp;nbsp;all. &lt;/p&gt;
&lt;p&gt;So what is it? Well, I think I just spoil the answer at the beginning. Yes! You guessed it! It is the Rank of this transformation. Why? Remember how the transformation matrix is defined? The column of the transformation matrix is the basis vectors after transformation. So the span of the &amp;#8220;transformed&amp;#8221; basis has to be the vector space &lt;span class="math"&gt;\(W\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There is another name for &lt;span class="math"&gt;\(W\)&lt;/span&gt;. For a linear transformation. Vector space &lt;span class="math"&gt;\(W\)&lt;/span&gt; is called the &lt;strong&gt;image&lt;/strong&gt; of transformation. It is the &amp;#8220;output&amp;#8221; of that&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;Alright! We now know the dimension of vector space before and after the transformation, there is only one part of the theorem&amp;nbsp;remains.&lt;/p&gt;
&lt;p&gt;When we looked at the dimension of &lt;span class="math"&gt;\(V\)&lt;/span&gt; and &lt;span class="math"&gt;\(W\)&lt;/span&gt;, you will notice that the dimension of &lt;span class="math"&gt;\(V\)&lt;/span&gt; is &lt;strong&gt;always&lt;/strong&gt; bigger or equal to the dimension of &lt;span class="math"&gt;\(W\)&lt;/span&gt;. This comes from the fact that linear transformation cannot map one vector to two different ones, just like in function, one &lt;span class="math"&gt;\(x\)&lt;/span&gt; value will always give you one &lt;span class="math"&gt;\(y\)&lt;/span&gt; value, so the domain will always bigger than the&amp;nbsp;range. &lt;/p&gt;
&lt;p&gt;This is not particularly interested, but one might ask another question: where did the &amp;#8220;missing&amp;#8221; dimension go? If your transformation transform a 3d space to a 1d space, the rest 2 dimension actually go to the &lt;strong&gt;Null space&lt;/strong&gt; of that transformation! This is the last piece of our Rank-Nullity&amp;nbsp;theorem:&lt;/p&gt;
&lt;div class="math"&gt;$$Rank(T) + Nullity(T) = dim(V) = n$$&lt;/div&gt;
&lt;p&gt;How is this useful in practice? Well, once we know the rank of a transformation, we can quickly tell the dimension of its null space, and this works for unknown matrix too. Even if we don&amp;#8217;t know the exact transformation in the future, by applying the Rank-Nullity Theorem, we can know the dimension of image space or null&amp;nbsp;space. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>5-6 assignments</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/5-6-assignments" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/5-6-assignments</id><summary type="html">&lt;ol&gt;
&lt;li&gt;Solve the linear system by using Gaussian&amp;nbsp;elimination:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp; 0 &amp;amp; 1\\
1 &amp;amp; 1 &amp;amp; 0\\
1 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} = \begin{bmatrix}
1\\
2\\
3
\end{bmatrix}$$&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Find the inverse of the above matrix by using Gaussian elimination, write down the rank …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;ol&gt;
&lt;li&gt;Solve the linear system by using Gaussian&amp;nbsp;elimination:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp; 0 &amp;amp; 1\\
1 &amp;amp; 1 &amp;amp; 0\\
1 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} = \begin{bmatrix}
1\\
2\\
3
\end{bmatrix}$$&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Find the inverse of the above matrix by using Gaussian elimination, write down the rank of the matrix and explain why you get &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; didn&amp;#8217;t get solutions for question&amp;nbsp;1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solve the system without using Gaussian&amp;nbsp;elimination:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp; 0 &amp;amp; 1\\
1 &amp;amp; 1 &amp;amp; 0\\
1 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} = \begin{bmatrix}
2\\
3\\
4
\end{bmatrix}$$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 5 Solving Linear system using matrix"></category></entry><entry><title>6-1 Matrix and matrix multiplication</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/6-1-matrix-and-matrix-multiplication" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/6-1-matrix-and-matrix-multiplication</id><summary type="html">&lt;p&gt;In this Chapter we will work with matrix and matrix multiplication. Of course, just learn how to multiply the matrices together is not going to be the goal of this chapter. But to learn more powerful tools in linear algebra, we need to start from&amp;nbsp;basics.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this Chapter we will work with matrix and matrix multiplication. Of course, just learn how to multiply the matrices together is not going to be the goal of this chapter. But to learn more powerful tools in linear algebra, we need to start from&amp;nbsp;basics.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at two matrix multiplication with vectors &lt;span class="math"&gt;\(A\pmb{x} = \pmb{b}\)&lt;/span&gt;&amp;nbsp;:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix}\begin{bmatrix}
1 \\
0
\end{bmatrix} = \begin{bmatrix}
1 \\
3 
\end{bmatrix}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix}\begin{bmatrix}
\color{red}{0} \\
\color{red}{1}
\end{bmatrix} = \begin{bmatrix}
\color{red}{2} \\
\color{red}{4}
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;If we combine the vectors into a matrix, and do the same thing with both vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; and vector &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;, we will get&amp;nbsp;:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 2\\
3 &amp;amp; 4
\end{bmatrix}\begin{bmatrix}
1 &amp;amp; \color{red}{0} \\
0 &amp;amp; \color{red}{1}
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; \color{red}{2} \\
3 &amp;amp; \color{red}{4}
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So here you are! This is the way of multiplying matrices! Although we don&amp;#8217;t know what it is mean or what is it for yet, we can still see something out of&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;First you can see that the &amp;#8220;shape&amp;#8221; of matrix is quite important here. Just like when we do transformation, we cannot make a 3 by 3 transformation matrix to transform a 1d vector. To multiply two matrices, the matrices must have certain&amp;nbsp;&amp;#8220;shape&amp;#8221;.&lt;/p&gt;
&lt;p&gt;If we think about matrix &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; matrix multiplication as the combination of many column vector transformation, then like transformation, the size of input column vector must agree with the size of transformation matrix, to be specific, the column number of the first matrix must be the same as the size of input column vector. Which happens to be the row number of the second&amp;nbsp;matrix. &lt;/p&gt;
&lt;p&gt;But how about the row number of the first matrix and the column number of the second matrix? Are they useful? Well yes!, they are just happens to be the dimension of the result matrix! The row number of the first matrix became the dimension of output vector and the column number of the second matrix tells you how many of them are combining together to form the final&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;All of the details above seems complicate and hard to memorize, but here is one good thing about math, you don&amp;#8217;t have to memorize them at all! Just write down any matrix and start multiplying them and combining the vectors. You will figure out all the details by yourself! Also Luckily, we hardly work with non-square matrices, and for square matrices, rules are pretty simple: &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; matrix can only multiply the square matrix with the same size (&lt;span class="math"&gt;\(n \times n\)&lt;/span&gt;) and the result will be another &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt;&amp;nbsp;matrix.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 6 Matrix and Matrix multiplication"></category></entry><entry><title>6-2 The “Steps” in Gaussian elimination</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/6-2-the-steps-in-gaussian-elimination" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/6-2-the-steps-in-gaussian-elimination</id><summary type="html">&lt;p&gt;Last time, we learned how to multiply two matrices. In this section, we can finally put this into application. The first application we will do is the elementary&amp;nbsp;matrices.&lt;/p&gt;
&lt;p&gt;Remember the way we solve the linear system? We use Gaussian elimination. Let&amp;#8217;s look at a example and see if …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last time, we learned how to multiply two matrices. In this section, we can finally put this into application. The first application we will do is the elementary&amp;nbsp;matrices.&lt;/p&gt;
&lt;p&gt;Remember the way we solve the linear system? We use Gaussian elimination. Let&amp;#8217;s look at a example and see if we can understand the process in a new point of&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;Assume we are going to solve the below&amp;nbsp;system:
&lt;/p&gt;
&lt;div class="math"&gt;$$
\left[
  \begin{matrix}
    2 &amp;amp; 4  \\
    1 &amp;amp; 1  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;The way we solve it is to do some row operation, namely you take one row in the matrix and replace it with a modified version of it or you swap two rows. There are two ways to modify the rows, which is adding and multiplying. Let&amp;#8217;s take a look at one row&amp;nbsp;operation.&lt;/p&gt;
&lt;div class="math"&gt;$$ \color{red}{(1)}\rightarrow \frac{1}{2} \times\color{red}{(1)} $$&lt;/div&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 &amp;amp; 4\\
1 &amp;amp; 1
\end{bmatrix}\rightarrow\begin{bmatrix}
1 &amp;amp; 2\\
1 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now think about this: We learned the way of multiplying matrix and vector, the multiplication transformed that vector to another vector. So, can we write the above transformation as a matrix &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; matrix&amp;nbsp;multiplication? &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at the columns before and after&amp;nbsp;transform:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 \\
1 
\end{bmatrix}\rightarrow\begin{bmatrix}
1 \\
1 
\end{bmatrix}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
4\\
1
\end{bmatrix}\rightarrow\begin{bmatrix}
2\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The &amp;#8220;transformation&amp;#8221; only made x value to be a half and leaved the y value, so if we are going to write the &amp;#8220;transformation&amp;#8221;, it should&amp;nbsp;be:&lt;/p&gt;
&lt;div class="math"&gt;$$E_1 = \begin{bmatrix}
\frac{1}{2} &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;We can check it by multiplying the two&amp;nbsp;matrices:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
\frac{1}{2} &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix}\begin{bmatrix}
2 &amp;amp; 4\\
1 &amp;amp; 1
\end{bmatrix} = \begin{bmatrix}
\frac{1}{2}\times2 &amp;amp; \frac{1}{2}\times4\\
1\times1 &amp;amp; 1\times1
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; 2\\
1 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Great, now we know that we can describe the row operation as a specific matrix multiply on it. Actually, their is a name for that type of matrix, it is called &lt;strong&gt;elementary matrix&lt;/strong&gt;. We can try to write down more elementary matrix in 2d and see what they looks&amp;nbsp;like.&lt;/p&gt;
&lt;p&gt;Say we want to add the second row to the first row and replace the first one, what should we&amp;nbsp;do?&lt;/p&gt;
&lt;p&gt;We first start with an identity matrix. For 2d, the matrix will be a &lt;span class="math"&gt;\(2\times2\)&lt;/span&gt;&amp;nbsp;matrix.&lt;/p&gt;
&lt;div class="math"&gt;$$I_{2\times2}= \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now let&amp;#8217;s replace the first&amp;nbsp;row:&lt;/p&gt;
&lt;div class="math"&gt;$$E_2 =\begin{bmatrix}
1+0 &amp;amp; 0+1\\
0 &amp;amp; 1
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; 1\\
0 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Similarly, we can describe the swapping using elementary&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$E_3 = \begin{bmatrix}
0 &amp;amp; 1\\
1 &amp;amp; 0
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;For now, elementary matrix is just a fancy way to write down the row operation of matrices. But why do we need such way to describe row operation? Let&amp;#8217;s look at one of the application of row operation, the Gaussian&amp;nbsp;elimination.&lt;/p&gt;
&lt;p&gt;Remember we solve linear system &lt;span class="math"&gt;\(A\pmb{x}=\pmb{b}\)&lt;/span&gt; using the Gaussian elimination? What if we rewrite all the row operation to elementary matrices? We start with writing the augmented&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$A|\pmb{b}=  
\left[
  \begin{matrix}
    2 &amp;amp; -1  \\
    1 &amp;amp; 1  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      2  \\
      1  
    \end{matrix}
  \right.
\right]
$$&lt;/div&gt;
&lt;p&gt;Then we did some row operations to make the matrix to be the identity&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$A\rightarrow E_nE_{n-1}...E_2E_1A = I$$&lt;/div&gt;
&lt;p&gt;At the same time, we do the same operations onn the vector &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{b}\rightarrow E_nE_{n-1}...E_2E_1\pmb{b}$$&lt;/div&gt;
&lt;p&gt;If you take all the elementary matrice and multiply all of them together, we&amp;nbsp;get:&lt;/p&gt;
&lt;div class="math"&gt;$$E_nE_{n-1}...E_2E_1A = E_{total}A= I$$&lt;/div&gt;
&lt;p&gt;Notice the definition of a matrix&amp;#8217;s inverse&amp;nbsp;is:&lt;/p&gt;
&lt;div class="math"&gt;$$A^{-1}A = AA^{-1}= I$$&lt;/div&gt;
&lt;p&gt;So, the matrix &lt;span class="math"&gt;\(E_{total}\)&lt;/span&gt; is exactly the inverse matrix of &lt;span class="math"&gt;\(A\)&lt;/span&gt;! Once we know that, we can replace the elementary matrices into &lt;span class="math"&gt;\(A^{-1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$E_nE_{n-1}...E_2E_1\pmb{b} = E_{total}\pmb{b} = A^{-1}\pmb{b} = \pmb{x}$$&lt;/div&gt;
&lt;p&gt;Well, this is exactly the method we used in the inverse matrix unit. Great! Let&amp;#8217;s see if we can do&amp;nbsp;more.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;The second time that we used the row operation is to find the inverse of a matrix. Back then, we didn&amp;#8217;t explain why the method work, now we learned the elementary matrices, we can see what actually&amp;nbsp;happens.&lt;/p&gt;
&lt;p&gt;To find the inverse, we first place the matrix and the identity matrix with the same size&amp;nbsp;together:&lt;/p&gt;
&lt;div class="math"&gt;$$A|I = \left[
  \begin{matrix}
    1 &amp;amp; 2  \\
    3 &amp;amp; 4  
  \end{matrix}
  \left|
    \,
    \begin{matrix}
      1 &amp;amp; 0 \\
      0 &amp;amp; 1 
    \end{matrix}
  \right.
\right] $$&lt;/div&gt;
&lt;p&gt;Then we do Gaussian elimination for both side. The goal is to make the left side of augmented matrix to be identity&amp;nbsp;matrix.&lt;/p&gt;
&lt;div class="math"&gt;$$A \rightarrow I $$&lt;/div&gt;
&lt;p&gt;We can write the row operation as multiple elementary&amp;nbsp;matrices:
&lt;/p&gt;
&lt;div class="math"&gt;$$E_nE_{n-1}...E_2E_1A = I$$&lt;/div&gt;
&lt;p&gt;Again, it is obvious that &lt;span class="math"&gt;\(E_nE_{n-1}...E_2E_1 =A^{-1}\)&lt;/span&gt; so if we do the same row operations on the right side of augmented matrix(the identity matrix), we will&amp;nbsp;get:&lt;/p&gt;
&lt;div class="math"&gt;$$ I \rightarrow E_nE_{n-1}...E_2E_1I = A^{-1}I = A^{-1}$$&lt;/div&gt;
&lt;p&gt;That is why we end up with the inverse of matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 6 Matrix and Matrix multiplication"></category></entry><entry><title>6-3 Row Reduced Echelon Form</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/6-3-row-reduced-echelon-form" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/6-3-row-reduced-echelon-form</id><summary type="html">&lt;p&gt;We already saw several interesting thing we can do with Matrix and Matrix multiplication, in this section, we will learn a very famous matrix. This matrix is always introduced at the first class of linear algebra, but here we are going to try a very special&amp;nbsp;approach.&lt;/p&gt;
&lt;p&gt;Assume we have …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We already saw several interesting thing we can do with Matrix and Matrix multiplication, in this section, we will learn a very famous matrix. This matrix is always introduced at the first class of linear algebra, but here we are going to try a very special&amp;nbsp;approach.&lt;/p&gt;
&lt;p&gt;Assume we have a lovely matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;, where &lt;span class="math"&gt;\(A\)&lt;/span&gt; has some interesting&amp;nbsp;columns:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
2 &amp;amp; -1 &amp;amp; 1\\
1 &amp;amp; 1 &amp;amp; 2\\
1 &amp;amp; 2 &amp;amp; 3
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The columns of matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt; has some relations, namely the first column plus the second column gives you the third&amp;nbsp;column:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2 \\
1 \\
1 
\end{bmatrix}+\begin{bmatrix}
-1\\
1\\
2 
\end{bmatrix} = \begin{bmatrix}
1\\
2\\
3 
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;What do we know about the columns of this matrix? We know that the real &amp;#8220;meat&amp;#8221; of the matrix is the first two columns, since the last column is the linear combination of the first&amp;nbsp;two. &lt;/p&gt;
&lt;p&gt;So, how about we deconstruct this matrix into two? where the first matrix contain all the &amp;#8220;meat&amp;#8221; of the matrix (here the &amp;#8220;meat&amp;#8221; just means the basis of column space), and the second matrix tells us all the other information, like the last column is the first column plus the second&amp;nbsp;column?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s do&amp;nbsp;this!&lt;/p&gt;
&lt;p&gt;first matrix is easy! We just get rid of the last column and call it &lt;span class="math"&gt;\(C\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$C = \begin{bmatrix}
2 &amp;amp; -1 \\
1 &amp;amp; 1 \\
1 &amp;amp; 2 
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;then we write the &amp;#8220;bone&amp;#8221; of this matrix using the basis &lt;span class="math"&gt;\(C\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;How do we construct it? We can immediately tell that to get the first column &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2 \\
1 \\
1 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;, we need just one portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2 \\
1 \\
1 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and zero portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1\\
2 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. In another word, one portion of the first basis vector and zero of the&amp;nbsp;second:&lt;/p&gt;
&lt;div class="math"&gt;$$R_1 = \begin{bmatrix}
1 \\
0 
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;To get the second column vector, we need zero portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2 \\
1 \\
1 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and one portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1\\
2 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. In another word, one portion of the first basis vector and zero of the&amp;nbsp;second:&lt;/p&gt;
&lt;div class="math"&gt;$$R_2 = \begin{bmatrix}
0 \\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;At last, To get the third column vector, we need one portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2 \\
1 \\
1 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and one portion of &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1\\
2 
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. In another word, one portion of the first basis vector and zero of the&amp;nbsp;second:&lt;/p&gt;
&lt;div class="math"&gt;$$R_3 = \begin{bmatrix}
1 \\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Now we put these three &amp;#8220;bones&amp;#8221; together, and we call the combination matrix &lt;span class="math"&gt;\(R\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$R = \begin{bmatrix}
1 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 1 &amp;amp; 1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;You can check that the matrix &lt;span class="math"&gt;\(C\)&lt;/span&gt; multiply by the matrix &lt;span class="math"&gt;\(R\)&lt;/span&gt; is exactly the matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;!&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
2 &amp;amp; -1 &amp;amp; 1\\
1 &amp;amp; 1 &amp;amp; 2\\
1 &amp;amp; 2 &amp;amp; 3
\end{bmatrix} = \begin{bmatrix}
2 &amp;amp; -1 \\
1 &amp;amp; 1 \\
1 &amp;amp; 2 
\end{bmatrix}\begin{bmatrix}
1 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 1 &amp;amp; 1
\end{bmatrix} = CR$$&lt;/div&gt;
&lt;p&gt;Here comes the cool part. Do you know why we name the &amp;#8220;bone&amp;#8221; matrix &lt;span class="math"&gt;\(R\)&lt;/span&gt;? The &lt;span class="math"&gt;\(R\)&lt;/span&gt; stand for row, if you learned the Gaussian elimination before, you will notice that this matrix looks like the result of the Gaussian elimination, the &lt;strong&gt;Row Echelon Form&lt;/strong&gt;! Specifically, in this case, we get the &lt;strong&gt;Reduced Row Echelon Form&lt;/strong&gt; of matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;We can do this for any matrix. When you do it on the square matrix with all independent columns(rows), the Reduced Row Echelon Form(&lt;span class="caps"&gt;RREF&lt;/span&gt;) is just the identity&amp;nbsp;matrix. &lt;/p&gt;
&lt;p&gt;So, not only we can combine two matrix into one, we can also decompose a matrix into many. This specific example is called &lt;span class="caps"&gt;CR&lt;/span&gt; factorization, there are more of them in the future, like &lt;span class="caps"&gt;LU&lt;/span&gt; decomposition or diagonalization. Each of them plays an important role in linear&amp;nbsp;algebra.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 6 Matrix and Matrix multiplication"></category></entry><entry><title>6-4 Change the basis</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/6-4-change-the-basis" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/6-4-change-the-basis</id><summary type="html">&lt;p&gt;Now comes to one of the biggest applications of Matrix multiplication. Sometimes we we solve a problem, we might find that the classic Cartesian coordinate is not the best coordinate to work with. For example, let start with some random point on the Cartesian coordinate and form a line&amp;nbsp;segment …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Now comes to one of the biggest applications of Matrix multiplication. Sometimes we we solve a problem, we might find that the classic Cartesian coordinate is not the best coordinate to work with. For example, let start with some random point on the Cartesian coordinate and form a line&amp;nbsp;segment:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6example" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6example.png" /&gt;&lt;/p&gt;
&lt;p&gt;Say we want to find the tip of the bar after a rotation of 15 degree, to do this normally takes quite a lot of work. But, if we convert the point &lt;span class="math"&gt;\((3,1)\)&lt;/span&gt; to the polar coordinate, and then we do the rotation. After that, we can covert the transformed polar coordinate into Cartesian&amp;nbsp;coordinate.&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6example" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;So, can we do the same in linear algebra? Can we change one vector in one coordinate(basis) to another&amp;nbsp;one? &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s start with a vector in the classic Cartesian coordinate, pick any two number, let&amp;#8217;s say &lt;span class="math"&gt;\((2,1)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The basis of Cartesian coordinate is vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}1 \\ 0 \end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
0\\
1\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;, so the meaning of vector 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; is just two pieces of 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1\\
0
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and one piece of 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
0\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
2\\
1
\end{bmatrix} = 2\times\begin{bmatrix}
1\\
0
\end{bmatrix} + 1\times\begin{bmatrix}
0\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;&lt;img alt="w6vector" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6vector.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here we have another 2d basis create by spanning vector 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and 
&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6basis" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6basis.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this new basis, our vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
\color{red}2\\
\color{red}1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; will no longer looks the same as the vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in Cartesian coordinate. We can do a quick calculation to see what is &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
\color{red}2\\
\color{red}1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in the new&amp;nbsp;basis:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{\color{red}v} = 2\times\begin{bmatrix}
1\\
1
\end{bmatrix} + 1\times\begin{bmatrix}
1\\
-2
\end{bmatrix} = \begin{bmatrix}
3\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;To not make you confuse, I will label all the vectors lie in Cartesian coordinate black, and the vector lie in new coordinate&amp;nbsp;red.&lt;/p&gt;
&lt;p&gt;So the question is, what should be the vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in our new basis? In another word, how many &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; combined together will give you &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;? &lt;/p&gt;
&lt;p&gt;You might find the statements here are kind of confusing, so I will help you out by showing you the solution&amp;nbsp;first:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6changebasis" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6changebasis.png" /&gt;&lt;/p&gt;
&lt;p&gt;It turns out, if you take &lt;span class="math"&gt;\(\color{red}{\frac{5}{3}}\)&lt;/span&gt; of vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and &lt;span class="math"&gt;\(\color{red}{\frac{1}{3}}\)&lt;/span&gt; of vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1\\
-2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;, you will end up with vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. So our vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in the new basis has a new name &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now how do I got these number out? Think about this, if we rewrite the above relation in a matrix form, we will&amp;nbsp;have:&lt;/p&gt;
&lt;div class="math"&gt;$$\color{red}{\frac{5}{3}}\times\begin{bmatrix}
1\\
1
\end{bmatrix}+\color{red}{\frac{1}{3}}\times\begin{bmatrix}
1\\
-2
\end{bmatrix} = \begin{bmatrix}
2\\
1
\end{bmatrix}\rightarrow\begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}\begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix} = \begin{bmatrix}
2\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;It looks like the matrix &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; can transformed our &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; back to what it was in Cartesian coordinate. What do we want is to know what is &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in new basis, so we have to find the&amp;nbsp;inverse:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}\begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix} = \begin{bmatrix}
2\\
1
\end{bmatrix} \rightarrow \begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}^{-1}\begin{bmatrix}
2\\
1
\end{bmatrix}= \begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Strange, right? To know the presentation in one specific basis, you have to apply the inverse transformation. but this is what it&amp;nbsp;is.&lt;/p&gt;
&lt;p&gt;For the previous example, the way we get &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
\color{red}{\frac{5}{3}}\\
\color{red}{\frac{1}{3}}
\end{bmatrix}&lt;/div&gt; $ is by first put our basis vector together and form the matrix $&lt;div class="math"&gt;\begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;, then we can find its&amp;nbsp;inverse:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
1 &amp;amp; 1\\
1 &amp;amp; -2
\end{bmatrix}^{-1} = \begin{bmatrix}
\frac{2}{3} &amp;amp; \frac{1}{3}\\
\frac{1}{3} &amp;amp; -\frac{1}{3}
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;And the last step is to put any vector we want to transform in it and do a&amp;nbsp;multiplication.&lt;/p&gt;
&lt;p&gt;Can we do it for any basis? Here is the animation I made that shows the vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
2\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; in different&amp;nbsp;basis:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6any" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w6any.gif" /&gt;&lt;/p&gt;
&lt;p&gt;Now we know how to convert a vector in another basis, let&amp;#8217;s do something fun&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;Assume you have some transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt; in some basis. For example, the Cartesian coordinate. The transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt; has a dimension of &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt;. Let&amp;#8217;s say we have a vector lies in the Cartesian coordinate called &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt; and if you transform that vector, you will get vector &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$T\pmb{a} = \pmb{b}$$&lt;/div&gt;
&lt;p&gt;Here comes the cool part. Instead of doing this transform in the old, boring Cartesian coordinate, why not do it in a new fancy basis? The basis vectors of this new basis form a matrix &lt;span class="math"&gt;\(P\)&lt;/span&gt;. We can rewrite the vector &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; in our new&amp;nbsp;basis:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{a}' = P^{-1}\pmb{a}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\pmb{b}' = P^{-1}\pmb{b}$$&lt;/div&gt;
&lt;p&gt;We know the fact that you can use the transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt; to transform &lt;span class="math"&gt;\(\pmb{a}\)&lt;/span&gt; to &lt;span class="math"&gt;\(\pmb{b}\)&lt;/span&gt; but you can see that wouldn&amp;#8217;t work in our new basis. Namely, you cannot apply the same transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt; on &lt;span class="math"&gt;\(\pmb{a}'\)&lt;/span&gt; to give you &lt;span class="math"&gt;\(\pmb{b}'\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{a}' = P^{-1}\pmb{a}$$&lt;/div&gt;
&lt;div class="math"&gt;$$T\pmb{a}' = TP^{-1}\pmb{a} \neq \pmb{b}'$$&lt;/div&gt;
&lt;p&gt;So we need a new &amp;#8220;look&amp;#8221; of our transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt; in the new basis. We shall name it &lt;span class="math"&gt;\(T'\)&lt;/span&gt;, so&amp;nbsp;that:&lt;/p&gt;
&lt;div class="math"&gt;$$T'\pmb{a}' = \pmb{b}'$$&lt;/div&gt;
&lt;p&gt;With some simple algebra, we can get the expression of &lt;span class="math"&gt;\(T'\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$T'\pmb{a}' = \pmb{b}'$$&lt;/div&gt;
&lt;div class="math"&gt;$$T'\pmb{a}' = P^{-1}\pmb{b}$$&lt;/div&gt;
&lt;div class="math"&gt;$$T'\pmb{a}' = P^{-1}T\pmb{a}$$&lt;/div&gt;
&lt;div class="math"&gt;$$T'\pmb{a}' = P^{-1}TP\pmb{a}'$$&lt;/div&gt;
&lt;div class="math"&gt;$$T' = P^{-1}TP$$&lt;/div&gt;
&lt;p&gt;We can see that the way we rewrite a transformation for new basis is kind of different than vector. To understand the expression of &lt;span class="math"&gt;\(T' = P^{-1}TP\)&lt;/span&gt; is not hard. Imagine you are doing business in the other country. The transformation is the business process(Take some money and return some money). &lt;span class="math"&gt;\(T'\)&lt;/span&gt; and &lt;span class="math"&gt;\(T\)&lt;/span&gt; is just the same business process but in different country. say one in &lt;span class="caps"&gt;US&lt;/span&gt; one in &lt;span class="caps"&gt;UK&lt;/span&gt;. The matrix &lt;span class="math"&gt;\(P\)&lt;/span&gt; convert one currency to another, in our case dollar to pound. So if you are American and want to do the business in &lt;span class="caps"&gt;US&lt;/span&gt;, all you need is the transformation &lt;span class="math"&gt;\(T\)&lt;/span&gt;. But if you are a gentleman from &lt;span class="caps"&gt;UK&lt;/span&gt;, The same business process became&amp;nbsp;to:&lt;/p&gt;
&lt;p&gt;1) Convert the money to dollar (&lt;span class="math"&gt;\(P\)&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;2) Do the business in &lt;span class="caps"&gt;US&lt;/span&gt; (&lt;span class="math"&gt;\(T\)&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;3) Convert the dollar you earned in &lt;span class="caps"&gt;US&lt;/span&gt; back to pound and enjoy your life (&lt;span class="math"&gt;\(P^{-1}\)&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;So overall, what you did&amp;nbsp;is:&lt;/p&gt;
&lt;div class="math"&gt;$$\pmb{a} \rightarrow P\pmb{a} \rightarrow TP\pmb{a} \rightarrow P^{-1}TP\pmb{a}$$&lt;/div&gt;
&lt;p&gt;and that is the process &lt;span class="math"&gt;\(T'\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Notice that what we are dealing with is the &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; case. We can generalized this idea to any dimensions, but that is not what we focus here. Most of the time, we will be working on &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; case, especially &lt;span class="math"&gt;\(3 \times 3\)&lt;/span&gt; or &lt;span class="math"&gt;\(4 \times 4\)&lt;/span&gt; for&amp;nbsp;physics. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 6 Matrix and Matrix multiplication"></category></entry><entry><title>7-1 Eigenvalue and Eigenvector</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/7-1-eigenvalue-and-eigenvector" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/7-1-eigenvalue-and-eigenvector</id><summary type="html">&lt;p&gt;So far, we have been working on many matrices. We also learned that the cool notation &amp;#8220;matrix&amp;#8221; can describe a lot of things: linear equations, transformation, rotation, change the basis&amp;#8230; We can rely on matrix to do a lot of calculation that couldn&amp;#8217;t be done or hard to describe …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So far, we have been working on many matrices. We also learned that the cool notation &amp;#8220;matrix&amp;#8221; can describe a lot of things: linear equations, transformation, rotation, change the basis&amp;#8230; We can rely on matrix to do a lot of calculation that couldn&amp;#8217;t be done or hard to describe before. However, in real life, even if we use the matrix to cheat, the questions can still be really hard and tedious. In this chapter, we will be focusing on &lt;span class="caps"&gt;ONE&lt;/span&gt; way to make our life easier. Also, it turns out, this specific method has a huge impact on many many&amp;nbsp;area. &lt;/p&gt;
&lt;p&gt;Our main character has a German name: &lt;strong&gt;Eigen&lt;/strong&gt;. It is not because the guy who invent this is a German, but because David Hilbert, a German mathematician gave him this classic German name. From then, everyone start calling him&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Although this idea is first arose in the study of quadratic forms and differential equations, we are not going to take that approach. Instead, let&amp;#8217;s first define what it is, and then see what can this bad boy&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;So let&amp;#8217;s look at an example&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;If we treat this matrix as a transformation, applying this transformation on any 2d vector will give you another 2d vector. But this is not a new story, we did this before a billion times. What is interesting is that for some vectors in 2d space, their direction will not change after the transformation. What does that mean algebraically? Assume for some vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt;, we have the&amp;nbsp;relation:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \lambda\pmb{x}$$&lt;/div&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; is some non zero scalar value. Notice this value is just tells us how the vector is been &amp;#8220;stretched&amp;#8221; or &amp;#8220;compressed&amp;#8221;. If the &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; turns out to be negative, it just means the direction is&amp;nbsp;reversed.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s look at one of such vector. In our case, if we input vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and calculate the vector after the transformation, we&amp;nbsp;get:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}\begin{bmatrix}
-1\\
1
\end{bmatrix} = \begin{bmatrix}
-1\\
1
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;What a coincident! If we multiply 2 on both side, we&amp;nbsp;get:&lt;/p&gt;
&lt;div class="math"&gt;$$2\times A\pmb{x} = 2\begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}\begin{bmatrix}
-1\\
1
\end{bmatrix} = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}\begin{bmatrix}
-2\\
2
\end{bmatrix} = \begin{bmatrix}
-2\\
2
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;What does the above equation means? It means not only the vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; can do that, but any multiple of vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; also satisfy the equation &lt;span class="math"&gt;\(A\pmb{x} = \lambda\pmb{x}\)&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;For this specific vector, our vector stay the same after the transformation. So, &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; in this case is just &lt;span class="math"&gt;\(1\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;If we can find such vector and the corresponding &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; that satisfy the equation &lt;span class="math"&gt;\(A\pmb{x} = \lambda\pmb{x}\)&lt;/span&gt;. Then we call the vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; the &lt;strong&gt;Eigenvector&lt;/strong&gt; of our matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;, and we call the value &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; the corresponding &lt;strong&gt;Eigenvalue&lt;/strong&gt; of the&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;Great, now we know what does that means algebraically. Can we visualize&amp;nbsp;this?&lt;/p&gt;
&lt;p&gt;If you take the transformation and graph the change on different vector input, you will get something looks like&amp;nbsp;this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="w6example" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/trans_eigenvalue.gif" /&gt;&lt;/p&gt;
&lt;p&gt;As we expected, the vector&lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; and all the vectors along that line stays on that line after the transformation. But if you pay more attention, along the y-axis, the vectors do not change their direction too. We can check it by multiplying any vector along&amp;nbsp;y-axis:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x}' = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}\begin{bmatrix}
0\\
1
\end{bmatrix} =\begin{bmatrix}
0\\
2
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So any vector on y-axis will get doubled after the transformation. What does that means? Well, that vector didn&amp;#8217;t change the direction(still pointing along y-axis) so it is obviously another eigenvector of our matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;. What is the eigenvalue corresponding to that eigenvector? Since the vectors get doubled, then the eigenvalue must be&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;Wonderful! We have two different eigenvectors and eigenvalues for a single matrix. Can we find more? Unfortunately, we can&amp;#8217;t in this case. Later on, we will know why that is the&amp;nbsp;case. &lt;/p&gt;
&lt;p&gt;Now, you might wondering, does that means the eigenvectors and eigenvalues exist for any matrices? If so, how could we find them without guessing? We will leave that question to the future&amp;nbsp;chapter.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 7 Eigenvector, eigenvalue and Diagonalization"></category></entry><entry><title>7-2 Characteristic polynomials</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/7-2-characteristic-polynomials" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/7-2-characteristic-polynomials</id><summary type="html">&lt;p&gt;Last time, we learned a special vector for linear transformation: Eigenvector. But, there are two questions we didn&amp;#8217;t&amp;nbsp;answer.&lt;/p&gt;
&lt;p&gt;One, Is there always eigenvector and eigenvalues for&amp;nbsp;matrices?&lt;/p&gt;
&lt;p&gt;Second, How do we calculate&amp;nbsp;them?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s start from the definition of eigenvector and&amp;nbsp;eigenvalue:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \lambda\pmb …&lt;/div&gt;</summary><content type="html">&lt;p&gt;Last time, we learned a special vector for linear transformation: Eigenvector. But, there are two questions we didn&amp;#8217;t&amp;nbsp;answer.&lt;/p&gt;
&lt;p&gt;One, Is there always eigenvector and eigenvalues for&amp;nbsp;matrices?&lt;/p&gt;
&lt;p&gt;Second, How do we calculate&amp;nbsp;them?&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s start from the definition of eigenvector and&amp;nbsp;eigenvalue:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} = \lambda\pmb{x}$$&lt;/div&gt;
&lt;p&gt;If this equation hold for some vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; and non-zero value &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;, then great! We found the eigenvector and eigenvalues for that&amp;nbsp;matrix.&lt;/p&gt;
&lt;p&gt;To solve this, let&amp;#8217;s try to move all the terms on one&amp;nbsp;side:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} - \lambda\pmb{x} = 0$$&lt;/div&gt;
&lt;p&gt;Notice that we only know the matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;, so we need some way to combine these two terms. Factoring out vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; seems to be a good idea, but is there any way to factor out the vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Yes! We know the fact that for the square matrix with the same&amp;nbsp;size:&lt;/p&gt;
&lt;div class="math"&gt;$$(A+B)\pmb{x} = A\pmb{x}+B\pmb{x}$$&lt;/div&gt;
&lt;p&gt;So if we can rewrite number &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; into a matrix with the same size as &lt;span class="math"&gt;\(A\)&lt;/span&gt;, then we can combine the matrices and factor out &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt;. But how do we  rewrite number to a matrix? That is not hard since this number is multiplying on a vector, We can add a linear transformation that does nothing in front of vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\lambda\pmb{x} = \lambda I\pmb{x} = (\lambda I)\pmb{x} $$&lt;/div&gt;
&lt;p&gt;Now, the scalar &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; is a linear transformation &lt;span class="math"&gt;\(\lambda I\)&lt;/span&gt;, therefore, we can add the matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt; and the new matrix &lt;span class="math"&gt;\(\lambda I\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$A\pmb{x} - \lambda I\pmb{x} = 0$$&lt;/div&gt;
&lt;div class="math"&gt;$$(A- \lambda I)\pmb{x} = 0$$&lt;/div&gt;
&lt;p&gt;The new matrix &lt;span class="math"&gt;\((A- \lambda I)\)&lt;/span&gt; multiply some vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt; gives you zero vector. How do we find the vector &lt;span class="math"&gt;\(\pmb{x}\)&lt;/span&gt;? Easy! This is just ask you to find the null space of matrix &lt;span class="math"&gt;\((A- \lambda I)\)&lt;/span&gt;! &lt;/p&gt;
&lt;p&gt;Before, to find null space, we need to solve the linear system &lt;span class="math"&gt;\(A\pmb{x} = 0\)&lt;/span&gt;. But in our case, the matrix itself has some unknown variable in it, which is the number &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;. So how could we find the null space of a unknown&amp;nbsp;matrix?&lt;/p&gt;
&lt;p&gt;Here we will introduce a technique that we didn&amp;#8217;t mention before, call &lt;strong&gt;determinant&lt;/strong&gt;. In short, the determinant calculate the ratio between the size of space before and after the linear transformation. In 2d, it is simply the ratio between the area before and after the linear transformation. To calculate determinant for any &lt;span class="math"&gt;\(2\times2\)&lt;/span&gt; matrix, we just need to&amp;nbsp;do:&lt;/p&gt;
&lt;div class="math"&gt;$$det(A) = \begin{vmatrix}
a &amp;amp; b\\
c &amp;amp; d \\
\end{vmatrix} = ad - bc$$&lt;/div&gt;
&lt;p&gt;We are not going to cover the method of finding &lt;span class="math"&gt;\(3\times3\)&lt;/span&gt; or higher dimension matrix&amp;#8217;s determinant in this chapter. Feel free to search them up and think about&amp;nbsp;why. &lt;/p&gt;
&lt;p&gt;Why is find the ratio of area useful in our case? Because if a non-zero null space exist for a matrix, the the determinant of this matrix must be&amp;nbsp;zero. &lt;/p&gt;
&lt;p&gt;Why? By the rank-nullity theorem, if null space has dimension greater than zero, it means our rank is less than the dimension of matrix. So the linear transformation will transform the space to a space with lower&amp;nbsp;dimension. &lt;/p&gt;
&lt;p&gt;If the matrix is &lt;span class="math"&gt;\(2\times2\)&lt;/span&gt; but the rank is lower than 2, for example, is 1. It just means the matrix will transform any 2d vector to a 2d vector on a line (1d). So what will be the ratio of area before and after the transformation? Obviously is zero(The whole 2d plane was &amp;#8220;smash&amp;#8221; into a&amp;nbsp;line).&lt;/p&gt;
&lt;p&gt;Great! Now is time to put everything together and calculate some eigenvalue &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; eigenvector! Let&amp;#8217;s find the eigenvalue &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; eigenvector for the matrix we discussed last&amp;nbsp;time:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;The first thing we do is to get the matrix &lt;span class="math"&gt;\(A - \lambda I\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$A - \lambda I = \begin{bmatrix}
1 &amp;amp; 0\\
1 &amp;amp; 2 \\
\end{bmatrix}-\lambda \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 1 \\
\end{bmatrix} = \begin{bmatrix}
1-\lambda  &amp;amp; 0\\
1 &amp;amp; 2-\lambda  \\
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Then, we write down the determinant of this&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{vmatrix}
1-\lambda  &amp;amp; 0\\
1 &amp;amp; 2-\lambda  \\
\end{vmatrix} = (1-\lambda )(2-\lambda) - 0\times1 = (1-\lambda )(2-\lambda)$$&lt;/div&gt;
&lt;p&gt;To solve &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;, we just need to set this expression to zero. But before we do that, look at this familiar expression! It is a quadratic! Later, you will see that the determinant of &lt;span class="math"&gt;\(A - \lambda I\)&lt;/span&gt; will always be a polynomial. We have a special name for this: the &lt;strong&gt;Characteristic polynomials&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In our case, this polynomials is extremely easy to&amp;nbsp;solve:&lt;/p&gt;
&lt;div class="math"&gt;$$(1-\lambda )(2-\lambda) = 0 $$&lt;/div&gt;
&lt;div class="math"&gt;$$\downarrow$$&lt;/div&gt;
&lt;div class="math"&gt;$$\lambda_1 = 1$$&lt;/div&gt;
&lt;div class="math"&gt;$$\lambda_2 = 2$$&lt;/div&gt;
&lt;p&gt;So, &lt;span class="math"&gt;\(\lambda_1 = 1\)&lt;/span&gt; and &lt;span class="math"&gt;\(\lambda_2 = 2\)&lt;/span&gt; are the eigenvalue of the matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt;. To solve the eigenvector correspond to these eigenvalue, we just plug these back into our matrix &lt;span class="math"&gt;\(A - \lambda I\)&lt;/span&gt; and find the null&amp;nbsp;space:&lt;/p&gt;
&lt;div class="math"&gt;$$A - \lambda_1 I = \begin{bmatrix}
1 -1&amp;amp; 0\\
1 &amp;amp; 2 -1 \\
\end{bmatrix} = \begin{bmatrix}
0 &amp;amp; 0\\
1 &amp;amp; 1 \\
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;To find the null space, we solve the linear system &lt;span class="math"&gt;\(A\pmb{x} = 0\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
0 &amp;amp; 0\\
1 &amp;amp; 1 \\
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}= 0$$&lt;/div&gt;
&lt;div class="math"&gt;$$\downarrow$$&lt;/div&gt;
&lt;div class="math"&gt;$$  
\begin{cases}
      0x+0y\ =\ 0 \\
      x+y\ =\ 0 
    \end{cases}  \rightarrow  x = -y \rightarrow span{\begin{bmatrix}
-1\\
1
\end{bmatrix}}
$$&lt;/div&gt;
&lt;p&gt;Therefore, the eigenvector correspond to eigenvalue &lt;span class="math"&gt;\(1\)&lt;/span&gt; is vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
-1\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;. Using the same method, we can get the eigenvector for eigenvalue &lt;span class="math"&gt;\(\lambda_2 = 2\)&lt;/span&gt; is vector &lt;span class="math"&gt;\(&lt;div class="math"&gt;\begin{bmatrix}
0\\
1
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Awesome! We solved all the eigenvalue and their eigenvector. Does that means we solved everything? Of course not. Remember, we got lucky when solving the polynomial. Let&amp;#8217;s go back to the characteristic polynomial and see what are we&amp;nbsp;missing.&lt;/p&gt;
&lt;p&gt;The characteristic polynomial we had is &lt;span class="math"&gt;\((1-\lambda )(2-\lambda)\)&lt;/span&gt;, but in principle, we could have any polynomials. Take &lt;span class="math"&gt;\(2\times2\)&lt;/span&gt; matrix as example, our characteristic polynomial will be a&amp;nbsp;quadratic:&lt;/p&gt;
&lt;div class="math"&gt;$$a\lambda^2 + b\lambda + c= 0$$&lt;/div&gt;
&lt;p&gt;For our case, we ended up with two distinct &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; values. But we could also have two same &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; values or no real &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;The two same &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; values case is not that interesting. In 2d, the transformation that has only one eigenvalue will looks like a shear transformation. The interesting case is when we have no real &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;&amp;nbsp;values. &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s imaging: What kind of transformation in 2d that has no eigenvector? Having eigenvectors means there are some directions where all the vector alone that direction do not change its direction after the transformation. So, having no eigenvector means all the vector in 2d change its direction after the transformation. Did we see any of the transformation that can do&amp;nbsp;this?&lt;/p&gt;
&lt;p&gt;Of course! Any transformation that rotate the&amp;nbsp;plane!&lt;/p&gt;
&lt;p&gt;&lt;img alt="w4rotation" src="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/images/w4rotation.gif" /&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s take the very first linear transformation we saw. As you can see, all the vector do not end up with the same direction after the&amp;nbsp;transformation.&lt;/p&gt;
&lt;p&gt;If you learned the imaginary number before(don&amp;#8217;t worry if you never learn it, but I highly recommend you check it out online if you never), you will know that the quadratic that has no real solution will have imaginary solution. So our eigenvalue will be imaginary. In fact, imaginary eigenvalue will always has something to do with the rotation. However, Imaginary eigenvalue is beyond the scope of our&amp;nbsp;note.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 7 Eigenvector, eigenvalue and Diagonalization"></category></entry><entry><title>7-3 Diagonal matrix and transpose</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/7-3-diagonal-matrix-and-transpose" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/7-3-diagonal-matrix-and-transpose</id><summary type="html">&lt;p&gt;From the last chapter, we learned the way to compute the eigenvectors and eigenvalues of a matrix. We also learned the geometric meaning of eigenvectors and eigenvalues. You might say: Sure, here is the eigenvectors and eigenvalues of a matrix. So what? What is the&amp;nbsp;application?&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t worry! You …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From the last chapter, we learned the way to compute the eigenvectors and eigenvalues of a matrix. We also learned the geometric meaning of eigenvectors and eigenvalues. You might say: Sure, here is the eigenvectors and eigenvalues of a matrix. So what? What is the&amp;nbsp;application?&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t worry! You will find out the good stuff real soon. But for now, we have to learn one interesting type of matrix, which is related to the &amp;#8220;good stuff&amp;#8221;&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;The special matrix is called the diagonal matrix. The name &amp;#8220;diagonal&amp;#8221; comes from the fact that the matrix only has non-zero entry on the &amp;#8220;diagonal&amp;#8221; of the square&amp;nbsp;matrix:&lt;/p&gt;
&lt;div class="math"&gt;$$ A = \begin{bmatrix}
    x_{11} &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots  &amp;amp; 0 \\
    0 &amp;amp; x_{22} &amp;amp; 0 &amp;amp; \dots  &amp;amp; 0 \\
    0 &amp;amp; 0 &amp;amp; x_{33} &amp;amp; \dots  &amp;amp; 0 \\
    \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
    0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots  &amp;amp; x_{nn}
\end{bmatrix}
$$&lt;/div&gt;
&lt;p&gt;In convention, we call the the entries that has the same column and row number &amp;#8220;diagonal&amp;#8221; terms. and the entries that has the different column and row number &amp;#8220;off-diagonal&amp;#8221; terms. For diagonal matrix, First, it is usually a &lt;span class="math"&gt;\(n\times n\)&lt;/span&gt; matrix (we don&amp;#8217;t consider the &amp;#8220;rectangular&amp;#8221; ones&amp;#8221;). Second, all the &amp;#8220;off-diagonal&amp;#8221; terms must be zero. Notice that the diagonal terms doesn&amp;#8217;t have to be&amp;nbsp;zero.&lt;/p&gt;
&lt;p&gt;Great, this matrix looks &lt;span class="caps"&gt;VERY&lt;/span&gt; simple! Indeed, it is very easy to work with. Let&amp;#8217;s look at an interesting&amp;nbsp;example:&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s say there is a matrix &lt;span class="math"&gt;\(A = &lt;div class="math"&gt;\begin{bmatrix}
1 &amp;amp; 2 \\
3 &amp;amp; 4
\end{bmatrix}&lt;/div&gt; $, then what is $A^2\)&lt;/span&gt;&amp;nbsp;?&lt;/p&gt;
&lt;p&gt;We can do a quick matrix multiplication to get the answer for&amp;nbsp;that:&lt;/p&gt;
&lt;div class="math"&gt;$$A^2 = \begin{bmatrix}
1 &amp;amp; 2 \\
3 &amp;amp; 4
\end{bmatrix} \begin{bmatrix}
1 &amp;amp; 2 \\
3 &amp;amp; 4
\end{bmatrix} = \begin{bmatrix}
1 + 6 &amp;amp; 2 + 8 \\
3 + 12 &amp;amp; 6 + 16
\end{bmatrix} = \begin{bmatrix}
7 &amp;amp; 10 \\
15 &amp;amp; 22
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Well that was a breeze. But what if someone ask you, what is &lt;span class="math"&gt;\(A^{201}\)&lt;/span&gt; ? Then we are screwed. However, if you ask the same question on a diagonal matrix &lt;span class="math"&gt;\(D\)&lt;/span&gt;&amp;nbsp;:&lt;/p&gt;
&lt;div class="math"&gt;$$ D = \begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 2
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;the result of &lt;span class="math"&gt;\(D^{201}\)&lt;/span&gt; is&amp;nbsp;simply:&lt;/p&gt;
&lt;div class="math"&gt;$$ D^{201} = \begin{bmatrix}
1^{201} &amp;amp; 0\\
0 &amp;amp; 2^{201}
\end{bmatrix} $$&lt;/div&gt;
&lt;p&gt;Not only that, if you tried to find the eigenvalue of a diagonal matrix, you will soon realized the characteristic polynomials of a diagonal matrix is extremely&amp;nbsp;simple.&lt;/p&gt;
&lt;p&gt;If take matrix &lt;span class="math"&gt;\(D = &lt;div class="math"&gt;\begin{bmatrix}
1 &amp;amp; 0\\
0 &amp;amp; 2
\end{bmatrix}&lt;/div&gt;\)&lt;/span&gt; as a example. The characteristic polynomials is&amp;nbsp;just:&lt;/p&gt;
&lt;div class="math"&gt;$$det(D-\lambda I) = det(\begin{bmatrix}
1-\lambda &amp;amp; 0\\
0 &amp;amp; 2-\lambda
\end{bmatrix}) = (1-\lambda)(2-\lambda) = 0$$&lt;/div&gt;
&lt;p&gt;This tells us the eigenvalue right away, &lt;span class="math"&gt;\(\lambda = 1\)&lt;/span&gt; or &lt;span class="math"&gt;\(\lambda = 2\)&lt;/span&gt;. Which happens to be the diagonal terms of the matrix. Also, the eigenvectors of the matrix are easy too(Try to find them by&amp;nbsp;yourself).&lt;/p&gt;
&lt;p&gt;Alright! We now learned everything we need for the grand finale. In the next section, we are going to combine all the pieces and construct one of the most powerful weapons in linear algebra:&amp;nbsp;Diagonalization. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Chapter 7 Eigenvector, eigenvalue and Diagonalization"></category></entry><entry><title>7-4 Diagonalization</title><link href="https://davidnie-xiaonan.github.io/Linear_Algebra_note_David_Pelican/7-4-diagonalization" rel="alternate"></link><published>2021-09-11T10:20:00-04:00</published><updated>2021-12-05T19:30:00-05:00</updated><author><name>David Nie</name></author><id>tag:davidnie-xiaonan.github.io,2021-09-11:/Linear_Algebra_note_David_Pelican/7-4-diagonalization</id><content type="html">&lt;p&gt;Last time, we learned a special matrix called diagonal matrix. We knew that if a matrix is a diagonal matrix, everything will be extremely easy to&amp;nbsp;solve.&lt;/p&gt;</content><category term="Chapter 7 Eigenvector, eigenvalue and Diagonalization"></category></entry></feed>